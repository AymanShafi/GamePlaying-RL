{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    31/50000: episode: 1, duration: 1.729s, episode steps: 31, steps per second: 18, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: 0.013 [-1.185, 1.776], loss: 0.462173, mean_absolute_error: 0.520752, mean_q: 0.096439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"DQN_metrics.txt\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['episode: 1, duration: 1.729s, episode steps: 31, steps per second: 18, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.419 [0.000, 1.000], mean observation: 0.013 [-1.185, 1.776], loss: 0.462173, mean_absolute_error: 0.520752, mean_q: 0.096439\\n',\n",
       " 'episode: 2, duration: 0.084s, episode steps: 13, steps per second: 154, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.692 [0.000, 1.000], mean observation: -0.069 [-1.867, 1.224], loss: 0.352699, mean_absolute_error: 0.544416, mean_q: 0.290915\\n',\n",
       " 'episode: 3, duration: 0.142s, episode steps: 20, steps per second: 141, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: -0.070 [-1.375, 0.833], loss: 0.233226, mean_absolute_error: 0.553622, mean_q: 0.481963\\n',\n",
       " 'episode: 4, duration: 0.120s, episode steps: 19, steps per second: 158, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.421 [0.000, 1.000], mean observation: 0.074 [-0.817, 1.505], loss: 0.115771, mean_absolute_error: 0.604906, mean_q: 0.841101\\n',\n",
       " 'episode: 5, duration: 0.099s, episode steps: 15, steps per second: 151, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.600 [0.000, 1.000], mean observation: -0.090 [-1.368, 0.825], loss: 0.060949, mean_absolute_error: 0.689512, mean_q: 1.187350\\n',\n",
       " 'episode: 6, duration: 0.103s, episode steps: 16, steps per second: 156, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.750 [0.000, 1.000], mean observation: -0.069 [-2.711, 1.766], loss: 0.041591, mean_absolute_error: 0.727885, mean_q: 1.316640\\n',\n",
       " 'episode: 7, duration: 0.092s, episode steps: 14, steps per second: 153, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.111 [-0.934, 1.483], loss: 0.034899, mean_absolute_error: 0.761641, mean_q: 1.435475\\n',\n",
       " 'episode: 8, duration: 0.148s, episode steps: 23, steps per second: 156, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.304 [0.000, 1.000], mean observation: 0.050 [-1.760, 2.679], loss: 0.020848, mean_absolute_error: 0.825447, mean_q: 1.621850\\n',\n",
       " 'episode: 9, duration: 0.072s, episode steps: 11, steps per second: 153, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.133 [-1.133, 1.962], loss: 0.033472, mean_absolute_error: 0.876673, mean_q: 1.749073\\n',\n",
       " 'episode: 10, duration: 0.085s, episode steps: 13, steps per second: 153, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.769 [0.000, 1.000], mean observation: -0.118 [-2.439, 1.549], loss: 0.040221, mean_absolute_error: 0.940421, mean_q: 1.900732\\n',\n",
       " 'episode: 11, duration: 0.208s, episode steps: 33, steps per second: 159, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.424 [0.000, 1.000], mean observation: 0.004 [-1.381, 1.780], loss: 0.037214, mean_absolute_error: 0.993950, mean_q: 2.016667\\n',\n",
       " 'episode: 12, duration: 0.107s, episode steps: 15, steps per second: 140, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.096 [-1.845, 1.032], loss: 0.049411, mean_absolute_error: 1.103708, mean_q: 2.210941\\n',\n",
       " 'episode: 13, duration: 0.079s, episode steps: 12, steps per second: 152, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.124 [-1.329, 2.154], loss: 0.055344, mean_absolute_error: 1.173260, mean_q: 2.366916\\n',\n",
       " 'episode: 14, duration: 0.096s, episode steps: 14, steps per second: 146, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.103 [-0.965, 1.601], loss: 0.058532, mean_absolute_error: 1.220065, mean_q: 2.465080\\n',\n",
       " 'episode: 15, duration: 0.099s, episode steps: 15, steps per second: 152, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.086 [-1.187, 2.013], loss: 0.058335, mean_absolute_error: 1.309274, mean_q: 2.637853\\n',\n",
       " 'episode: 16, duration: 0.163s, episode steps: 25, steps per second: 153, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.360 [0.000, 1.000], mean observation: 0.054 [-1.365, 2.263], loss: 0.086458, mean_absolute_error: 1.378768, mean_q: 2.748358\\n',\n",
       " 'episode: 17, duration: 0.120s, episode steps: 19, steps per second: 158, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.684 [0.000, 1.000], mean observation: -0.100 [-2.458, 1.398], loss: 0.083784, mean_absolute_error: 1.489895, mean_q: 2.985679\\n',\n",
       " 'episode: 18, duration: 0.094s, episode steps: 14, steps per second: 149, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.100 [-1.382, 2.208], loss: 0.130680, mean_absolute_error: 1.577877, mean_q: 3.059857\\n',\n",
       " 'episode: 19, duration: 0.230s, episode steps: 37, steps per second: 161, episode reward: 37.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.541 [0.000, 1.000], mean observation: -0.011 [-1.245, 0.625], loss: 0.128095, mean_absolute_error: 1.673273, mean_q: 3.294010\\n',\n",
       " 'episode: 20, duration: 0.127s, episode steps: 18, steps per second: 141, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: 0.085 [-0.971, 1.471], loss: 0.150520, mean_absolute_error: 1.778720, mean_q: 3.481179\\n',\n",
       " 'episode: 21, duration: 0.060s, episode steps: 9, steps per second: 150, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.155 [-0.964, 1.743], loss: 0.160706, mean_absolute_error: 1.887498, mean_q: 3.698248\\n',\n",
       " 'episode: 22, duration: 0.268s, episode steps: 43, steps per second: 160, episode reward: 43.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.395 [0.000, 1.000], mean observation: 0.043 [-1.770, 2.753], loss: 0.146749, mean_absolute_error: 1.952648, mean_q: 3.832726\\n',\n",
       " 'episode: 23, duration: 0.097s, episode steps: 15, steps per second: 154, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.800 [0.000, 1.000], mean observation: -0.072 [-2.707, 1.794], loss: 0.179906, mean_absolute_error: 2.075476, mean_q: 4.121659\\n',\n",
       " 'episode: 24, duration: 0.101s, episode steps: 16, steps per second: 159, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.100 [-0.586, 1.215], loss: 0.149710, mean_absolute_error: 2.145880, mean_q: 4.209060\\n',\n",
       " 'episode: 25, duration: 0.156s, episode steps: 24, steps per second: 154, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: 0.040 [-0.805, 1.402], loss: 0.188366, mean_absolute_error: 2.244536, mean_q: 4.427539\\n',\n",
       " 'episode: 26, duration: 0.082s, episode steps: 13, steps per second: 158, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.108 [-0.766, 1.343], loss: 0.239616, mean_absolute_error: 2.327628, mean_q: 4.509193\\n',\n",
       " 'episode: 27, duration: 0.085s, episode steps: 13, steps per second: 152, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.231 [0.000, 1.000], mean observation: 0.085 [-1.384, 2.229], loss: 0.234737, mean_absolute_error: 2.413644, mean_q: 4.648050\\n',\n",
       " 'episode: 28, duration: 0.150s, episode steps: 22, steps per second: 146, episode reward: 22.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: -0.074 [-1.143, 0.733], loss: 0.181015, mean_absolute_error: 2.453977, mean_q: 4.747606\\n',\n",
       " 'episode: 29, duration: 0.098s, episode steps: 15, steps per second: 153, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.115 [-0.942, 1.773], loss: 0.192081, mean_absolute_error: 2.530632, mean_q: 4.949361\\n',\n",
       " 'episode: 30, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 10.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.100 [0.000, 1.000], mean observation: 0.138 [-1.524, 2.546], loss: 0.299307, mean_absolute_error: 2.586266, mean_q: 4.984053\\n',\n",
       " 'episode: 31, duration: 0.303s, episode steps: 48, steps per second: 158, episode reward: 48.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: -0.098 [-1.499, 0.480], loss: 0.223936, mean_absolute_error: 2.721186, mean_q: 5.230966\\n',\n",
       " 'episode: 32, duration: 0.092s, episode steps: 14, steps per second: 152, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.085 [-0.644, 1.246], loss: 0.222922, mean_absolute_error: 2.832808, mean_q: 5.451890\\n',\n",
       " 'episode: 33, duration: 0.077s, episode steps: 12, steps per second: 155, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.114 [-0.955, 1.508], loss: 0.280619, mean_absolute_error: 2.913803, mean_q: 5.594545\\n',\n",
       " 'episode: 34, duration: 0.146s, episode steps: 23, steps per second: 158, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.089 [-0.552, 1.284], loss: 0.238156, mean_absolute_error: 2.958582, mean_q: 5.649810\\n',\n",
       " 'episode: 35, duration: 0.096s, episode steps: 15, steps per second: 156, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.101 [-0.818, 1.565], loss: 0.282031, mean_absolute_error: 3.028489, mean_q: 5.751748\\n',\n",
       " 'episode: 36, duration: 0.146s, episode steps: 21, steps per second: 144, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.381 [0.000, 1.000], mean observation: 0.065 [-1.013, 1.852], loss: 0.211309, mean_absolute_error: 3.096119, mean_q: 5.967826\\n',\n",
       " 'episode: 37, duration: 0.291s, episode steps: 47, steps per second: 162, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.084 [-1.039, 0.965], loss: 0.269584, mean_absolute_error: 3.221706, mean_q: 6.217795\\n',\n",
       " 'episode: 38, duration: 0.073s, episode steps: 11, steps per second: 152, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.273 [0.000, 1.000], mean observation: 0.117 [-1.159, 1.986], loss: 0.222184, mean_absolute_error: 3.326948, mean_q: 6.508374\\n',\n",
       " 'episode: 39, duration: 0.250s, episode steps: 39, steps per second: 156, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: 0.073 [-0.626, 1.726], loss: 0.298241, mean_absolute_error: 3.398300, mean_q: 6.575160\\n',\n",
       " 'episode: 40, duration: 0.555s, episode steps: 89, steps per second: 160, episode reward: 89.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.082 [-0.958, 1.180], loss: 0.364272, mean_absolute_error: 3.668661, mean_q: 7.175972\\n',\n",
       " 'episode: 41, duration: 0.355s, episode steps: 56, steps per second: 158, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.174 [-0.882, 1.848], loss: 0.315008, mean_absolute_error: 3.977457, mean_q: 7.845994\\n',\n",
       " 'episode: 42, duration: 0.289s, episode steps: 46, steps per second: 159, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.457 [0.000, 1.000], mean observation: 0.011 [-0.847, 1.616], loss: 0.265045, mean_absolute_error: 4.197290, mean_q: 8.345032\\n',\n",
       " 'episode: 43, duration: 0.190s, episode steps: 27, steps per second: 142, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.556 [0.000, 1.000], mean observation: -0.005 [-1.245, 0.824], loss: 0.336632, mean_absolute_error: 4.344253, mean_q: 8.658427\\n',\n",
       " 'episode: 44, duration: 0.823s, episode steps: 118, steps per second: 143, episode reward: 118.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.122 [-1.103, 1.176], loss: 0.358444, mean_absolute_error: 4.652878, mean_q: 9.233859\\n',\n",
       " 'episode: 45, duration: 0.273s, episode steps: 36, steps per second: 132, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.097 [-0.549, 1.081], loss: 0.273760, mean_absolute_error: 5.033281, mean_q: 10.105188\\n',\n",
       " 'episode: 46, duration: 0.584s, episode steps: 82, steps per second: 140, episode reward: 82.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.074 [-1.273, 0.842], loss: 0.373407, mean_absolute_error: 5.276927, mean_q: 10.574589\\n',\n",
       " 'episode: 47, duration: 0.629s, episode steps: 87, steps per second: 138, episode reward: 87.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.218 [-1.813, 0.748], loss: 0.440016, mean_absolute_error: 5.681759, mean_q: 11.420763\\n',\n",
       " 'episode: 48, duration: 0.992s, episode steps: 136, steps per second: 137, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.179 [-1.319, 1.032], loss: 0.348960, mean_absolute_error: 6.169487, mean_q: 12.484807\\n',\n",
       " 'episode: 49, duration: 0.988s, episode steps: 139, steps per second: 141, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.518 [0.000, 1.000], mean observation: 0.250 [-1.317, 2.053], loss: 0.555011, mean_absolute_error: 6.824183, mean_q: 13.755137\\n',\n",
       " 'episode: 50, duration: 0.583s, episode steps: 80, steps per second: 137, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: -0.280 [-1.844, 0.590], loss: 0.708785, mean_absolute_error: 7.359047, mean_q: 14.836370\\n',\n",
       " 'episode: 51, duration: 1.346s, episode steps: 190, steps per second: 141, episode reward: 190.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.511 [0.000, 1.000], mean observation: 0.141 [-1.037, 1.354], loss: 0.902548, mean_absolute_error: 7.952768, mean_q: 16.040045\\n',\n",
       " 'episode: 52, duration: 0.820s, episode steps: 115, steps per second: 140, episode reward: 115.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.207 [-1.701, 1.052], loss: 0.943667, mean_absolute_error: 8.719868, mean_q: 17.599972\\n',\n",
       " 'episode: 53, duration: 0.706s, episode steps: 98, steps per second: 139, episode reward: 98.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.253 [-1.521, 1.105], loss: 0.656707, mean_absolute_error: 9.190284, mean_q: 18.648235\\n',\n",
       " 'episode: 54, duration: 0.842s, episode steps: 117, steps per second: 139, episode reward: 117.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.479 [0.000, 1.000], mean observation: -0.165 [-1.117, 0.884], loss: 1.004947, mean_absolute_error: 9.720198, mean_q: 19.663158\\n',\n",
       " 'episode: 55, duration: 0.789s, episode steps: 110, steps per second: 139, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.247 [-1.456, 0.667], loss: 0.985152, mean_absolute_error: 10.169116, mean_q: 20.541286\\n',\n",
       " 'episode: 56, duration: 0.602s, episode steps: 86, steps per second: 143, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.299 [-1.664, 0.955], loss: 1.342366, mean_absolute_error: 10.608091, mean_q: 21.390018\\n',\n",
       " 'episode: 57, duration: 0.775s, episode steps: 126, steps per second: 163, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.193 [-1.310, 0.843], loss: 1.244294, mean_absolute_error: 11.023990, mean_q: 22.256395\\n',\n",
       " 'episode: 58, duration: 0.678s, episode steps: 110, steps per second: 162, episode reward: 110.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.233 [-1.262, 0.819], loss: 1.042155, mean_absolute_error: 11.492437, mean_q: 23.283735\\n',\n",
       " 'episode: 59, duration: 1.662s, episode steps: 267, steps per second: 161, episode reward: 267.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.126 [-1.869, 0.887], loss: 1.176041, mean_absolute_error: 12.356016, mean_q: 25.056852\\n',\n",
       " 'episode: 60, duration: 0.764s, episode steps: 123, steps per second: 161, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.235 [-1.705, 0.713], loss: 1.065391, mean_absolute_error: 13.312965, mean_q: 27.054955\\n',\n",
       " 'episode: 61, duration: 0.703s, episode steps: 113, steps per second: 161, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.226 [-1.338, 1.151], loss: 0.972392, mean_absolute_error: 13.747091, mean_q: 28.004063\\n',\n",
       " 'episode: 62, duration: 0.692s, episode steps: 113, steps per second: 163, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.320 [-1.833, 0.767], loss: 1.314061, mean_absolute_error: 14.269607, mean_q: 28.984467\\n',\n",
       " 'episode: 63, duration: 0.761s, episode steps: 121, steps per second: 159, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.292 [-1.795, 0.709], loss: 1.246324, mean_absolute_error: 14.765546, mean_q: 30.033134\\n',\n",
       " 'episode: 64, duration: 0.746s, episode steps: 120, steps per second: 161, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.257 [-1.776, 0.741], loss: 1.543824, mean_absolute_error: 15.349784, mean_q: 31.205563\\n',\n",
       " 'episode: 65, duration: 0.716s, episode steps: 116, steps per second: 162, episode reward: 116.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.286 [-1.505, 0.787], loss: 0.965880, mean_absolute_error: 15.673398, mean_q: 31.941576\\n',\n",
       " 'episode: 66, duration: 0.801s, episode steps: 131, steps per second: 164, episode reward: 131.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.294 [-1.829, 0.799], loss: 1.647946, mean_absolute_error: 16.283972, mean_q: 33.066647\\n',\n",
       " 'episode: 67, duration: 0.802s, episode steps: 129, steps per second: 161, episode reward: 129.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.304 [-1.844, 0.868], loss: 1.891711, mean_absolute_error: 16.623253, mean_q: 33.813675\\n',\n",
       " 'episode: 68, duration: 0.875s, episode steps: 141, steps per second: 161, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.264 [-1.807, 0.833], loss: 1.241396, mean_absolute_error: 17.185675, mean_q: 34.949745\\n',\n",
       " 'episode: 69, duration: 0.765s, episode steps: 123, steps per second: 161, episode reward: 123.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.300 [-1.646, 0.771], loss: 1.240435, mean_absolute_error: 17.764503, mean_q: 36.197350\\n',\n",
       " 'episode: 70, duration: 0.936s, episode steps: 151, steps per second: 161, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.280 [-1.816, 0.729], loss: 1.568701, mean_absolute_error: 18.466053, mean_q: 37.530582\\n',\n",
       " 'episode: 71, duration: 0.944s, episode steps: 152, steps per second: 161, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.269 [-1.883, 1.028], loss: 1.594927, mean_absolute_error: 18.979239, mean_q: 38.589977\\n',\n",
       " 'episode: 72, duration: 1.044s, episode steps: 166, steps per second: 159, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.257 [-1.801, 0.824], loss: 1.363492, mean_absolute_error: 19.447481, mean_q: 39.564194\\n',\n",
       " 'episode: 73, duration: 0.750s, episode steps: 122, steps per second: 163, episode reward: 122.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.337 [-2.232, 0.567], loss: 1.587888, mean_absolute_error: 20.125023, mean_q: 40.867008\\n',\n",
       " 'episode: 74, duration: 1.012s, episode steps: 164, steps per second: 162, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.241 [-1.989, 0.912], loss: 1.735828, mean_absolute_error: 20.517803, mean_q: 41.782597\\n',\n",
       " 'episode: 75, duration: 0.909s, episode steps: 146, steps per second: 161, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.268 [-2.016, 0.812], loss: 1.342584, mean_absolute_error: 21.058399, mean_q: 42.885406\\n',\n",
       " 'episode: 76, duration: 1.395s, episode steps: 224, steps per second: 161, episode reward: 224.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.193 [-2.365, 0.993], loss: 1.706175, mean_absolute_error: 21.851994, mean_q: 44.299309\\n',\n",
       " 'episode: 77, duration: 0.798s, episode steps: 130, steps per second: 163, episode reward: 130.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.307 [-1.992, 0.856], loss: 1.523257, mean_absolute_error: 22.428846, mean_q: 45.553249\\n',\n",
       " 'episode: 78, duration: 1.237s, episode steps: 199, steps per second: 161, episode reward: 199.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.256 [-2.320, 0.797], loss: 1.798136, mean_absolute_error: 22.932577, mean_q: 46.612221\\n',\n",
       " 'episode: 79, duration: 1.062s, episode steps: 171, steps per second: 161, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.292 [-2.174, 0.883], loss: 1.627858, mean_absolute_error: 23.427000, mean_q: 47.651966\\n',\n",
       " 'episode: 80, duration: 0.946s, episode steps: 152, steps per second: 161, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.307 [-2.144, 0.699], loss: 1.927983, mean_absolute_error: 24.042112, mean_q: 48.805592\\n',\n",
       " 'episode: 81, duration: 1.131s, episode steps: 183, steps per second: 162, episode reward: 183.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.277 [-2.382, 0.923], loss: 2.003144, mean_absolute_error: 24.682772, mean_q: 50.121525\\n',\n",
       " 'episode: 82, duration: 1.075s, episode steps: 174, steps per second: 162, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.304 [-2.364, 0.997], loss: 2.027018, mean_absolute_error: 24.997238, mean_q: 50.735172\\n',\n",
       " 'episode: 83, duration: 1.118s, episode steps: 177, steps per second: 158, episode reward: 177.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.292 [-2.035, 0.897], loss: 2.397092, mean_absolute_error: 25.481846, mean_q: 51.701767\\n',\n",
       " 'episode: 84, duration: 1.120s, episode steps: 180, steps per second: 161, episode reward: 180.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.289 [-2.541, 0.873], loss: 1.726510, mean_absolute_error: 26.055420, mean_q: 52.955631\\n',\n",
       " 'episode: 85, duration: 1.648s, episode steps: 268, steps per second: 163, episode reward: 268.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.190 [-2.197, 0.957], loss: 1.677988, mean_absolute_error: 26.722757, mean_q: 54.278976\\n',\n",
       " 'episode: 86, duration: 1.168s, episode steps: 189, steps per second: 162, episode reward: 189.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.322 [-2.376, 0.824], loss: 1.744531, mean_absolute_error: 27.568590, mean_q: 56.006573\\n',\n",
       " 'episode: 87, duration: 1.104s, episode steps: 179, steps per second: 162, episode reward: 179.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.338 [-3.097, 1.150], loss: 1.989020, mean_absolute_error: 27.918995, mean_q: 56.639721\\n',\n",
       " 'episode: 88, duration: 1.045s, episode steps: 167, steps per second: 160, episode reward: 167.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.349 [-2.994, 1.097], loss: 2.377820, mean_absolute_error: 28.328569, mean_q: 57.343727\\n',\n",
       " 'episode: 89, duration: 1.279s, episode steps: 206, steps per second: 161, episode reward: 206.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.255 [-2.627, 1.272], loss: 2.063432, mean_absolute_error: 28.945963, mean_q: 58.720997\\n',\n",
       " 'episode: 90, duration: 0.894s, episode steps: 144, steps per second: 161, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.268 [-2.005, 0.962], loss: 2.174310, mean_absolute_error: 29.349663, mean_q: 59.513603\\n',\n",
       " 'episode: 91, duration: 1.103s, episode steps: 174, steps per second: 158, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.335 [-3.683, 2.062], loss: 2.551449, mean_absolute_error: 29.897852, mean_q: 60.494030\\n',\n",
       " 'episode: 92, duration: 1.296s, episode steps: 210, steps per second: 162, episode reward: 210.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.298 [-2.983, 1.291], loss: 2.263921, mean_absolute_error: 30.214550, mean_q: 61.201908\\n',\n",
       " 'episode: 93, duration: 0.982s, episode steps: 157, steps per second: 160, episode reward: 157.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.323 [-2.233, 1.059], loss: 2.099911, mean_absolute_error: 30.570278, mean_q: 61.997318\\n',\n",
       " 'episode: 94, duration: 1.078s, episode steps: 174, steps per second: 161, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.332 [-3.767, 2.381], loss: 2.580698, mean_absolute_error: 31.013582, mean_q: 62.963463\\n',\n",
       " 'episode: 95, duration: 1.671s, episode steps: 269, steps per second: 161, episode reward: 269.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.197 [-2.010, 0.934], loss: 3.365029, mean_absolute_error: 31.587200, mean_q: 64.088013\\n',\n",
       " 'episode: 96, duration: 1.432s, episode steps: 229, steps per second: 160, episode reward: 229.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.277 [-2.738, 1.252], loss: 2.531268, mean_absolute_error: 32.363853, mean_q: 65.658783\\n',\n",
       " 'episode: 97, duration: 1.010s, episode steps: 163, steps per second: 161, episode reward: 163.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.442 [0.000, 1.000], mean observation: -0.354 [-3.569, 2.198], loss: 3.215895, mean_absolute_error: 32.699547, mean_q: 66.243988\\n',\n",
       " 'episode: 98, duration: 1.406s, episode steps: 224, steps per second: 159, episode reward: 224.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: -0.268 [-3.706, 2.182], loss: 2.673188, mean_absolute_error: 33.406178, mean_q: 67.655579\\n',\n",
       " 'episode: 99, duration: 1.483s, episode steps: 240, steps per second: 162, episode reward: 240.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.270 [-2.427, 0.824], loss: 3.707894, mean_absolute_error: 33.718098, mean_q: 68.339729\\n',\n",
       " 'episode: 100, duration: 0.989s, episode steps: 155, steps per second: 157, episode reward: 155.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.246 [-1.521, 0.830], loss: 2.967485, mean_absolute_error: 34.170456, mean_q: 69.382172\\n',\n",
       " 'episode: 101, duration: 1.072s, episode steps: 171, steps per second: 159, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.450 [0.000, 1.000], mean observation: -0.359 [-3.140, 1.225], loss: 4.259010, mean_absolute_error: 34.722195, mean_q: 70.224426\\n',\n",
       " 'episode: 102, duration: 1.203s, episode steps: 193, steps per second: 160, episode reward: 193.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.310 [-3.561, 2.076], loss: 3.226599, mean_absolute_error: 34.913147, mean_q: 70.680672\\n',\n",
       " 'episode: 103, duration: 1.297s, episode steps: 207, steps per second: 160, episode reward: 207.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.302 [-3.143, 1.309], loss: 2.782929, mean_absolute_error: 35.428909, mean_q: 71.811310\\n',\n",
       " 'episode: 104, duration: 2.798s, episode steps: 452, steps per second: 162, episode reward: 452.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.161 [-0.855, 1.974], loss: 3.203374, mean_absolute_error: 36.197533, mean_q: 73.241585\\n',\n",
       " 'episode: 105, duration: 1.386s, episode steps: 220, steps per second: 159, episode reward: 220.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.293 [-2.775, 0.881], loss: 3.822625, mean_absolute_error: 37.098331, mean_q: 75.023262\\n',\n",
       " 'episode: 106, duration: 1.159s, episode steps: 186, steps per second: 160, episode reward: 186.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.343 [-2.390, 0.924], loss: 4.236228, mean_absolute_error: 37.428974, mean_q: 75.686623\\n',\n",
       " 'episode: 107, duration: 1.886s, episode steps: 298, steps per second: 158, episode reward: 298.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.216 [-2.412, 0.822], loss: 3.213909, mean_absolute_error: 37.960251, mean_q: 76.851250\\n',\n",
       " 'episode: 108, duration: 1.825s, episode steps: 295, steps per second: 162, episode reward: 295.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.340 [-0.784, 2.364], loss: 4.313341, mean_absolute_error: 38.760372, mean_q: 78.396080\\n',\n",
       " 'episode: 109, duration: 1.986s, episode steps: 320, steps per second: 161, episode reward: 320.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.318 [-0.756, 2.407], loss: 4.328205, mean_absolute_error: 39.918327, mean_q: 80.651352\\n',\n",
       " 'episode: 110, duration: 1.313s, episode steps: 210, steps per second: 160, episode reward: 210.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.312 [-2.420, 0.721], loss: 5.033235, mean_absolute_error: 40.775799, mean_q: 82.596901\\n',\n",
       " 'episode: 111, duration: 2.650s, episode steps: 429, steps per second: 162, episode reward: 429.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.249 [-0.986, 2.409], loss: 4.987158, mean_absolute_error: 41.481129, mean_q: 83.862305\\n',\n",
       " 'episode: 112, duration: 1.639s, episode steps: 258, steps per second: 157, episode reward: 258.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.256 [-2.409, 0.865], loss: 4.505596, mean_absolute_error: 42.670341, mean_q: 86.261353\\n',\n",
       " 'episode: 113, duration: 1.989s, episode steps: 318, steps per second: 160, episode reward: 318.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.370 [-0.871, 2.407], loss: 7.236184, mean_absolute_error: 43.157227, mean_q: 87.113602\\n',\n",
       " 'episode: 114, duration: 2.514s, episode steps: 403, steps per second: 160, episode reward: 403.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.279 [-1.115, 2.401], loss: 7.445703, mean_absolute_error: 44.356007, mean_q: 89.487396\\n',\n",
       " 'episode: 115, duration: 2.364s, episode steps: 328, steps per second: 139, episode reward: 328.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.344 [-0.761, 2.412], loss: 6.375701, mean_absolute_error: 45.284046, mean_q: 91.548927\\n',\n",
       " 'episode: 116, duration: 2.469s, episode steps: 343, steps per second: 139, episode reward: 343.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.356 [-0.860, 2.404], loss: 4.630236, mean_absolute_error: 46.188232, mean_q: 93.404755\\n',\n",
       " 'episode: 117, duration: 2.904s, episode steps: 397, steps per second: 137, episode reward: 397.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.321 [-0.817, 2.402], loss: 8.179825, mean_absolute_error: 47.240070, mean_q: 95.323227\\n',\n",
       " 'episode: 118, duration: 3.342s, episode steps: 492, steps per second: 147, episode reward: 492.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.312 [-0.689, 2.401], loss: 7.857806, mean_absolute_error: 48.487820, mean_q: 97.877922\\n',\n",
       " 'episode: 119, duration: 2.933s, episode steps: 468, steps per second: 160, episode reward: 468.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.320 [-0.863, 2.401], loss: 5.364316, mean_absolute_error: 49.516373, mean_q: 100.135735\\n',\n",
       " 'episode: 120, duration: 2.713s, episode steps: 432, steps per second: 159, episode reward: 432.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.343 [-0.918, 2.402], loss: 5.347921, mean_absolute_error: 50.844429, mean_q: 102.674225\\n',\n",
       " 'episode: 121, duration: 2.613s, episode steps: 418, steps per second: 160, episode reward: 418.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.361 [-0.658, 2.408], loss: 6.581341, mean_absolute_error: 51.713779, mean_q: 104.452927\\n',\n",
       " 'episode: 122, duration: 2.210s, episode steps: 354, steps per second: 160, episode reward: 354.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.386 [-0.697, 2.400], loss: 5.236181, mean_absolute_error: 52.439678, mean_q: 105.930511\\n',\n",
       " 'episode: 123, duration: 2.729s, episode steps: 434, steps per second: 159, episode reward: 434.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.350 [-0.775, 2.402], loss: 6.352950, mean_absolute_error: 53.019524, mean_q: 107.166168\\n',\n",
       " 'episode: 124, duration: 2.559s, episode steps: 405, steps per second: 158, episode reward: 405.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.391 [-0.789, 2.401], loss: 4.551521, mean_absolute_error: 53.598457, mean_q: 108.307762\\n',\n",
       " 'episode: 125, duration: 2.735s, episode steps: 436, steps per second: 159, episode reward: 436.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.388 [-0.651, 2.401], loss: 6.172012, mean_absolute_error: 54.385689, mean_q: 109.766907\\n',\n",
       " 'episode: 126, duration: 2.466s, episode steps: 392, steps per second: 159, episode reward: 392.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.375 [-0.655, 2.400], loss: 6.755196, mean_absolute_error: 55.021725, mean_q: 111.180328\\n',\n",
       " 'episode: 127, duration: 2.524s, episode steps: 404, steps per second: 160, episode reward: 404.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.363 [-0.709, 2.402], loss: 5.070217, mean_absolute_error: 55.589737, mean_q: 112.352402\\n',\n",
       " 'episode: 128, duration: 2.640s, episode steps: 416, steps per second: 158, episode reward: 416.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.413 [-0.682, 2.405], loss: 5.983955, mean_absolute_error: 56.272701, mean_q: 113.623177\\n',\n",
       " 'episode: 129, duration: 2.276s, episode steps: 364, steps per second: 160, episode reward: 364.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.378 [-0.801, 2.403], loss: 4.174394, mean_absolute_error: 56.506268, mean_q: 114.232018\\n',\n",
       " 'episode: 130, duration: 2.380s, episode steps: 378, steps per second: 159, episode reward: 378.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.401 [-0.757, 2.402], loss: 6.078301, mean_absolute_error: 57.095238, mean_q: 115.296173\\n',\n",
       " 'episode: 131, duration: 2.965s, episode steps: 467, steps per second: 157, episode reward: 467.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.408 [-0.791, 2.402], loss: 6.669725, mean_absolute_error: 57.707584, mean_q: 116.485741\\n',\n",
       " 'episode: 132, duration: 3.168s, episode steps: 500, steps per second: 158, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.498 [0.000, 1.000], mean observation: 0.424 [-0.693, 2.362], loss: 4.729326, mean_absolute_error: 57.635071, mean_q: 116.442787\\n',\n",
       " 'episode: 133, duration: 3.143s, episode steps: 500, steps per second: 159, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.403 [-0.821, 2.311], loss: 5.036013, mean_absolute_error: 57.700920, mean_q: 116.663795\\n',\n",
       " 'episode: 134, duration: 2.613s, episode steps: 416, steps per second: 159, episode reward: 416.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.352 [-0.974, 2.401], loss: 7.369270, mean_absolute_error: 57.960995, mean_q: 116.887787\\n',\n",
       " 'episode: 135, duration: 3.134s, episode steps: 500, steps per second: 160, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.498 [0.000, 1.000], mean observation: 0.376 [-0.828, 2.359], loss: 5.936100, mean_absolute_error: 58.215260, mean_q: 117.580521\\n',\n",
       " 'episode: 136, duration: 3.182s, episode steps: 500, steps per second: 157, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.391 [-0.822, 2.299], loss: 5.809545, mean_absolute_error: 57.976994, mean_q: 117.284454\\n',\n",
       " 'episode: 137, duration: 3.147s, episode steps: 500, steps per second: 159, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.358 [-0.904, 2.382], loss: 4.790256, mean_absolute_error: 58.269463, mean_q: 117.938515\\n',\n",
       " 'episode: 138, duration: 3.135s, episode steps: 500, steps per second: 159, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.387 [-0.956, 2.360], loss: 4.667628, mean_absolute_error: 58.719551, mean_q: 118.687004\\n',\n",
       " 'episode: 139, duration: 2.554s, episode steps: 399, steps per second: 156, episode reward: 399.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.340 [-1.043, 2.402], loss: 4.916703, mean_absolute_error: 58.614105, mean_q: 118.458801\\n',\n",
       " 'episode: 140, duration: 2.349s, episode steps: 374, steps per second: 159, episode reward: 374.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.313 [-0.934, 2.404], loss: 5.747376, mean_absolute_error: 58.734531, mean_q: 118.635338\\n',\n",
       " 'episode: 141, duration: 2.698s, episode steps: 427, steps per second: 158, episode reward: 427.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.345 [-1.159, 2.403], loss: 6.808571, mean_absolute_error: 58.877945, mean_q: 118.775085\\n',\n",
       " 'episode: 142, duration: 3.164s, episode steps: 500, steps per second: 158, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.292 [-0.936, 2.367], loss: 4.243455, mean_absolute_error: 59.070789, mean_q: 119.302307\\n',\n",
       " 'episode: 143, duration: 2.035s, episode steps: 316, steps per second: 155, episode reward: 316.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.378 [-1.142, 2.404], loss: 4.474892, mean_absolute_error: 58.989685, mean_q: 118.927231\\n',\n",
       " 'episode: 144, duration: 2.707s, episode steps: 393, steps per second: 145, episode reward: 393.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.324 [-0.811, 2.407], loss: 6.173388, mean_absolute_error: 59.190575, mean_q: 119.201515\\n',\n",
       " 'episode: 145, duration: 2.438s, episode steps: 328, steps per second: 135, episode reward: 328.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.376 [-1.048, 2.402], loss: 5.465988, mean_absolute_error: 59.256191, mean_q: 119.247543\\n',\n",
       " 'episode: 146, duration: 3.217s, episode steps: 438, steps per second: 136, episode reward: 438.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.279 [-1.050, 2.400], loss: 5.538434, mean_absolute_error: 58.917114, mean_q: 118.733772\\n',\n",
       " 'episode: 147, duration: 3.034s, episode steps: 421, steps per second: 139, episode reward: 421.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.305 [-0.822, 2.403], loss: 6.000508, mean_absolute_error: 58.645588, mean_q: 118.159012\\n',\n",
       " 'episode: 148, duration: 2.106s, episode steps: 330, steps per second: 157, episode reward: 330.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.368 [-1.123, 2.409], loss: 5.634782, mean_absolute_error: 58.481716, mean_q: 117.832092\\n',\n",
       " 'episode: 149, duration: 2.302s, episode steps: 363, steps per second: 158, episode reward: 363.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.326 [-0.952, 2.412], loss: 5.063807, mean_absolute_error: 58.597279, mean_q: 118.086388\\n',\n",
       " 'episode: 150, duration: 2.289s, episode steps: 357, steps per second: 156, episode reward: 357.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.324 [-1.223, 2.414], loss: 4.889977, mean_absolute_error: 58.595726, mean_q: 117.918114\\n',\n",
       " 'episode: 151, duration: 2.231s, episode steps: 352, steps per second: 158, episode reward: 352.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.325 [-0.984, 2.407], loss: 8.003345, mean_absolute_error: 58.194546, mean_q: 117.196625\\n',\n",
       " 'episode: 152, duration: 2.669s, episode steps: 416, steps per second: 156, episode reward: 416.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.297 [-1.019, 2.410], loss: 8.385610, mean_absolute_error: 57.755154, mean_q: 116.074829\\n',\n",
       " 'episode: 153, duration: 2.350s, episode steps: 367, steps per second: 156, episode reward: 367.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.325 [-1.241, 2.407], loss: 5.622941, mean_absolute_error: 57.645180, mean_q: 116.022324\\n',\n",
       " 'episode: 154, duration: 2.747s, episode steps: 431, steps per second: 157, episode reward: 431.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.291 [-1.021, 2.404], loss: 6.725824, mean_absolute_error: 57.383301, mean_q: 115.450333\\n',\n",
       " 'episode: 155, duration: 2.355s, episode steps: 371, steps per second: 158, episode reward: 371.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.338 [-1.246, 2.400], loss: 4.053256, mean_absolute_error: 56.873894, mean_q: 114.547318\\n',\n",
       " 'episode: 156, duration: 2.760s, episode steps: 429, steps per second: 155, episode reward: 429.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.312 [-0.958, 2.405], loss: 3.341397, mean_absolute_error: 57.095154, mean_q: 114.918106\\n',\n",
       " 'episode: 157, duration: 2.245s, episode steps: 346, steps per second: 154, episode reward: 346.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.332 [-1.290, 2.406], loss: 4.614096, mean_absolute_error: 56.782242, mean_q: 114.377281\\n',\n",
       " 'episode: 158, duration: 2.951s, episode steps: 458, steps per second: 155, episode reward: 458.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.291 [-1.214, 2.410], loss: 7.074708, mean_absolute_error: 56.650791, mean_q: 113.871704\\n',\n",
       " 'episode: 159, duration: 2.288s, episode steps: 356, steps per second: 156, episode reward: 356.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.339 [-1.235, 2.402], loss: 7.149241, mean_absolute_error: 56.349609, mean_q: 113.276276\\n',\n",
       " 'episode: 160, duration: 2.757s, episode steps: 427, steps per second: 155, episode reward: 427.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.312 [-0.978, 2.407], loss: 5.580923, mean_absolute_error: 56.293774, mean_q: 113.200951\\n',\n",
       " 'episode: 161, duration: 2.118s, episode steps: 332, steps per second: 157, episode reward: 332.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.353 [-1.229, 2.410], loss: 4.579061, mean_absolute_error: 56.028416, mean_q: 112.790619\\n',\n",
       " 'episode: 162, duration: 2.001s, episode steps: 313, steps per second: 156, episode reward: 313.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.355 [-1.141, 2.406], loss: 8.333429, mean_absolute_error: 55.917332, mean_q: 112.330887\\n',\n",
       " 'episode: 163, duration: 2.435s, episode steps: 382, steps per second: 157, episode reward: 382.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.327 [-0.962, 2.400], loss: 4.079334, mean_absolute_error: 55.588089, mean_q: 112.037430\\n',\n",
       " 'episode: 164, duration: 2.141s, episode steps: 328, steps per second: 153, episode reward: 328.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.341 [-1.382, 2.408], loss: 5.484010, mean_absolute_error: 55.531219, mean_q: 111.644554\\n',\n",
       " 'episode: 165, duration: 3.146s, episode steps: 431, steps per second: 137, episode reward: 431.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.298 [-1.392, 2.406], loss: 7.016966, mean_absolute_error: 55.541031, mean_q: 111.580917\\n',\n",
       " 'episode: 166, duration: 2.577s, episode steps: 341, steps per second: 132, episode reward: 341.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.330 [-1.578, 2.413], loss: 7.278677, mean_absolute_error: 55.330990, mean_q: 110.998260\\n',\n",
       " 'episode: 167, duration: 2.602s, episode steps: 398, steps per second: 153, episode reward: 398.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.302 [-1.137, 2.403], loss: 7.087126, mean_absolute_error: 55.133873, mean_q: 110.779327\\n',\n",
       " 'episode: 168, duration: 3.064s, episode steps: 471, steps per second: 154, episode reward: 471.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.303 [-1.504, 2.407], loss: 6.771763, mean_absolute_error: 54.837563, mean_q: 110.228409\\n',\n",
       " 'episode: 169, duration: 3.194s, episode steps: 496, steps per second: 155, episode reward: 496.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.238 [-1.318, 2.402], loss: 7.970106, mean_absolute_error: 54.635006, mean_q: 109.722847\\n',\n",
       " 'episode: 170, duration: 3.173s, episode steps: 491, steps per second: 155, episode reward: 491.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.250 [-1.706, 2.406], loss: 5.704204, mean_absolute_error: 54.260590, mean_q: 109.047600\\n',\n",
       " 'episode: 171, duration: 3.260s, episode steps: 500, steps per second: 153, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.220 [-1.271, 2.256], loss: 7.200768, mean_absolute_error: 54.098209, mean_q: 108.654381\\n',\n",
       " 'episode: 172, duration: 3.195s, episode steps: 500, steps per second: 157, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.041 [-1.220, 1.212], loss: 6.464919, mean_absolute_error: 54.360081, mean_q: 109.216179\\n',\n",
       " 'episode: 173, duration: 3.210s, episode steps: 500, steps per second: 156, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: 0.097 [-1.409, 1.360], loss: 6.186774, mean_absolute_error: 53.783821, mean_q: 108.131325\\n',\n",
       " 'episode: 174, duration: 2.934s, episode steps: 429, steps per second: 146, episode reward: 429.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.271 [-1.061, 2.407], loss: 4.830243, mean_absolute_error: 54.135418, mean_q: 108.937035\\n',\n",
       " 'episode: 175, duration: 3.759s, episode steps: 500, steps per second: 133, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.118 [-1.387, 1.362], loss: 7.292828, mean_absolute_error: 54.103619, mean_q: 108.625534\\n',\n",
       " 'episode: 176, duration: 3.546s, episode steps: 477, steps per second: 135, episode reward: 477.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.501 [0.000, 1.000], mean observation: 0.286 [-1.548, 2.405], loss: 6.350655, mean_absolute_error: 53.979561, mean_q: 108.621803\\n',\n",
       " 'episode: 177, duration: 3.436s, episode steps: 500, steps per second: 146, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.268 [-1.399, 2.237], loss: 6.235330, mean_absolute_error: 54.053059, mean_q: 108.718117\\n',\n",
       " 'episode: 178, duration: 3.254s, episode steps: 499, steps per second: 153, episode reward: 499.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.270 [-1.397, 2.414], loss: 5.833961, mean_absolute_error: 54.018051, mean_q: 108.660820\\n',\n",
       " 'episode: 179, duration: 3.228s, episode steps: 500, steps per second: 155, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.504 [0.000, 1.000], mean observation: 0.076 [-1.292, 1.461], loss: 6.821904, mean_absolute_error: 54.205986, mean_q: 109.010910\\n',\n",
       " 'episode: 180, duration: 3.224s, episode steps: 500, steps per second: 155, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.498 [0.000, 1.000], mean observation: -0.022 [-1.176, 0.976], loss: 5.201680, mean_absolute_error: 54.211395, mean_q: 109.014732\\n',\n",
       " 'episode: 181, duration: 3.300s, episode steps: 500, steps per second: 152, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.132 [-1.236, 1.502], loss: 6.375962, mean_absolute_error: 54.281094, mean_q: 109.005981\\n',\n",
       " 'episode: 182, duration: 3.970s, episode steps: 500, steps per second: 126, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.015 [-1.237, 0.930], loss: 6.382715, mean_absolute_error: 54.226540, mean_q: 108.944748\\n',\n",
       " 'episode: 183, duration: 3.962s, episode steps: 500, steps per second: 126, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.031 [-1.233, 1.178], loss: 5.900445, mean_absolute_error: 54.141014, mean_q: 108.887863\\n',\n",
       " 'episode: 184, duration: 3.617s, episode steps: 500, steps per second: 138, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.498 [0.000, 1.000], mean observation: -0.003 [-1.152, 0.911], loss: 5.648526, mean_absolute_error: 54.440849, mean_q: 109.243797\\n',\n",
       " 'episode: 185, duration: 2.857s, episode steps: 440, steps per second: 154, episode reward: 440.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.489 [0.000, 1.000], mean observation: -0.182 [-2.410, 0.987], loss: 4.240374, mean_absolute_error: 53.966129, mean_q: 108.517586\\n',\n",
       " 'episode: 186, duration: 2.159s, episode steps: 327, steps per second: 151, episode reward: 327.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.486 [0.000, 1.000], mean observation: -0.207 [-2.424, 0.788], loss: 2.932429, mean_absolute_error: 54.022423, mean_q: 108.469894\\n',\n",
       " 'episode: 187, duration: 3.268s, episode steps: 500, steps per second: 153, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.498 [0.000, 1.000], mean observation: 0.103 [-1.397, 1.507], loss: 5.913231, mean_absolute_error: 53.785702, mean_q: 108.030357\\n',\n",
       " 'episode: 188, duration: 3.357s, episode steps: 500, steps per second: 149, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.182 [-1.576, 1.619], loss: 5.370584, mean_absolute_error: 53.921318, mean_q: 108.256805\\n',\n",
       " 'episode: 189, duration: 2.998s, episode steps: 453, steps per second: 151, episode reward: 453.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.506 [0.000, 1.000], mean observation: 0.262 [-1.474, 2.401], loss: 4.394953, mean_absolute_error: 53.683739, mean_q: 107.851341\\n',\n",
       " 'episode: 190, duration: 2.901s, episode steps: 434, steps per second: 150, episode reward: 434.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.282 [-1.281, 2.410], loss: 4.740616, mean_absolute_error: 53.448002, mean_q: 107.293228\\n',\n",
       " 'episode: 191, duration: 3.267s, episode steps: 500, steps per second: 153, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.019 [-1.212, 1.065], loss: 5.950387, mean_absolute_error: 53.467194, mean_q: 107.309227\\n',\n",
       " 'episode: 192, duration: 3.276s, episode steps: 500, steps per second: 153, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.184 [-1.483, 2.013], loss: 3.836204, mean_absolute_error: 53.114296, mean_q: 106.746941\\n',\n",
       " 'episode: 193, duration: 2.010s, episode steps: 308, steps per second: 153, episode reward: 308.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.217 [-2.430, 1.068], loss: 3.644928, mean_absolute_error: 52.884850, mean_q: 106.207184\\n',\n",
       " 'episode: 194, duration: 3.304s, episode steps: 500, steps per second: 151, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.231 [-1.342, 2.188], loss: 4.523789, mean_absolute_error: 52.529846, mean_q: 105.522797\\n',\n",
       " 'episode: 195, duration: 2.282s, episode steps: 345, steps per second: 151, episode reward: 345.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.484 [0.000, 1.000], mean observation: -0.164 [-2.725, 0.979], loss: 5.533070, mean_absolute_error: 52.417603, mean_q: 105.200432\\n',\n",
       " 'episode: 196, duration: 1.627s, episode steps: 250, steps per second: 154, episode reward: 250.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.476 [0.000, 1.000], mean observation: -0.273 [-2.431, 1.368], loss: 3.804307, mean_absolute_error: 52.173004, mean_q: 104.850433\\n',\n",
       " 'episode: 197, duration: 2.597s, episode steps: 398, steps per second: 153, episode reward: 398.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.174 [-2.444, 0.990], loss: 4.982242, mean_absolute_error: 52.211079, mean_q: 104.764091\\n',\n",
       " 'episode: 198, duration: 3.312s, episode steps: 500, steps per second: 151, episode reward: 500.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.502 [0.000, 1.000], mean observation: 0.232 [-1.555, 2.110], loss: 6.029026, mean_absolute_error: 52.104034, mean_q: 104.495407']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(line[14:])\n",
    "new_lines\n",
    "# met_names = []\n",
    "# for met in new_lines[0].split(\",\"):\n",
    "#     met_names.append(met.split(\":\")[0])\n",
    "# met_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'episode': ' 1', ' episode steps': ' 31', ' episode reward': ' 31.000', ' loss': ' 0.462173', ' mean_absolute_error': ' 0.520752', ' mean_q': ' 0.09643'}, {'episode': ' 2', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.352699', ' mean_absolute_error': ' 0.544416', ' mean_q': ' 0.29091'}, {'episode': ' 3', ' episode steps': ' 20', ' episode reward': ' 20.000', ' loss': ' 0.233226', ' mean_absolute_error': ' 0.553622', ' mean_q': ' 0.48196'}, {'episode': ' 4', ' episode steps': ' 19', ' episode reward': ' 19.000', ' loss': ' 0.115771', ' mean_absolute_error': ' 0.604906', ' mean_q': ' 0.84110'}, {'episode': ' 5', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.060949', ' mean_absolute_error': ' 0.689512', ' mean_q': ' 1.18735'}, {'episode': ' 6', ' episode steps': ' 16', ' episode reward': ' 16.000', ' loss': ' 0.041591', ' mean_absolute_error': ' 0.727885', ' mean_q': ' 1.31664'}, {'episode': ' 7', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.034899', ' mean_absolute_error': ' 0.761641', ' mean_q': ' 1.43547'}, {'episode': ' 8', ' episode steps': ' 23', ' episode reward': ' 23.000', ' loss': ' 0.020848', ' mean_absolute_error': ' 0.825447', ' mean_q': ' 1.62185'}, {'episode': ' 9', ' episode steps': ' 11', ' episode reward': ' 11.000', ' loss': ' 0.033472', ' mean_absolute_error': ' 0.876673', ' mean_q': ' 1.74907'}, {'episode': ' 10', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.040221', ' mean_absolute_error': ' 0.940421', ' mean_q': ' 1.90073'}, {'episode': ' 11', ' episode steps': ' 33', ' episode reward': ' 33.000', ' loss': ' 0.037214', ' mean_absolute_error': ' 0.993950', ' mean_q': ' 2.01666'}, {'episode': ' 12', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.049411', ' mean_absolute_error': ' 1.103708', ' mean_q': ' 2.21094'}, {'episode': ' 13', ' episode steps': ' 12', ' episode reward': ' 12.000', ' loss': ' 0.055344', ' mean_absolute_error': ' 1.173260', ' mean_q': ' 2.36691'}, {'episode': ' 14', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.058532', ' mean_absolute_error': ' 1.220065', ' mean_q': ' 2.46508'}, {'episode': ' 15', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.058335', ' mean_absolute_error': ' 1.309274', ' mean_q': ' 2.63785'}, {'episode': ' 16', ' episode steps': ' 25', ' episode reward': ' 25.000', ' loss': ' 0.086458', ' mean_absolute_error': ' 1.378768', ' mean_q': ' 2.74835'}, {'episode': ' 17', ' episode steps': ' 19', ' episode reward': ' 19.000', ' loss': ' 0.083784', ' mean_absolute_error': ' 1.489895', ' mean_q': ' 2.98567'}, {'episode': ' 18', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.130680', ' mean_absolute_error': ' 1.577877', ' mean_q': ' 3.05985'}, {'episode': ' 19', ' episode steps': ' 37', ' episode reward': ' 37.000', ' loss': ' 0.128095', ' mean_absolute_error': ' 1.673273', ' mean_q': ' 3.29401'}, {'episode': ' 20', ' episode steps': ' 18', ' episode reward': ' 18.000', ' loss': ' 0.150520', ' mean_absolute_error': ' 1.778720', ' mean_q': ' 3.48117'}, {'episode': ' 21', ' episode steps': ' 9', ' episode reward': ' 9.000', ' loss': ' 0.160706', ' mean_absolute_error': ' 1.887498', ' mean_q': ' 3.69824'}, {'episode': ' 22', ' episode steps': ' 43', ' episode reward': ' 43.000', ' loss': ' 0.146749', ' mean_absolute_error': ' 1.952648', ' mean_q': ' 3.83272'}, {'episode': ' 23', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.179906', ' mean_absolute_error': ' 2.075476', ' mean_q': ' 4.12165'}, {'episode': ' 24', ' episode steps': ' 16', ' episode reward': ' 16.000', ' loss': ' 0.149710', ' mean_absolute_error': ' 2.145880', ' mean_q': ' 4.20906'}, {'episode': ' 25', ' episode steps': ' 24', ' episode reward': ' 24.000', ' loss': ' 0.188366', ' mean_absolute_error': ' 2.244536', ' mean_q': ' 4.42753'}, {'episode': ' 26', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.239616', ' mean_absolute_error': ' 2.327628', ' mean_q': ' 4.50919'}, {'episode': ' 27', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.234737', ' mean_absolute_error': ' 2.413644', ' mean_q': ' 4.64805'}, {'episode': ' 28', ' episode steps': ' 22', ' episode reward': ' 22.000', ' loss': ' 0.181015', ' mean_absolute_error': ' 2.453977', ' mean_q': ' 4.74760'}, {'episode': ' 29', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.192081', ' mean_absolute_error': ' 2.530632', ' mean_q': ' 4.94936'}, {'episode': ' 30', ' episode steps': ' 10', ' episode reward': ' 10.000', ' loss': ' 0.299307', ' mean_absolute_error': ' 2.586266', ' mean_q': ' 4.98405'}, {'episode': ' 31', ' episode steps': ' 48', ' episode reward': ' 48.000', ' loss': ' 0.223936', ' mean_absolute_error': ' 2.721186', ' mean_q': ' 5.23096'}, {'episode': ' 32', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.222922', ' mean_absolute_error': ' 2.832808', ' mean_q': ' 5.45189'}, {'episode': ' 33', ' episode steps': ' 12', ' episode reward': ' 12.000', ' loss': ' 0.280619', ' mean_absolute_error': ' 2.913803', ' mean_q': ' 5.59454'}, {'episode': ' 34', ' episode steps': ' 23', ' episode reward': ' 23.000', ' loss': ' 0.238156', ' mean_absolute_error': ' 2.958582', ' mean_q': ' 5.64981'}, {'episode': ' 35', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.282031', ' mean_absolute_error': ' 3.028489', ' mean_q': ' 5.75174'}, {'episode': ' 36', ' episode steps': ' 21', ' episode reward': ' 21.000', ' loss': ' 0.211309', ' mean_absolute_error': ' 3.096119', ' mean_q': ' 5.96782'}, {'episode': ' 37', ' episode steps': ' 47', ' episode reward': ' 47.000', ' loss': ' 0.269584', ' mean_absolute_error': ' 3.221706', ' mean_q': ' 6.21779'}, {'episode': ' 38', ' episode steps': ' 11', ' episode reward': ' 11.000', ' loss': ' 0.222184', ' mean_absolute_error': ' 3.326948', ' mean_q': ' 6.50837'}, {'episode': ' 39', ' episode steps': ' 39', ' episode reward': ' 39.000', ' loss': ' 0.298241', ' mean_absolute_error': ' 3.398300', ' mean_q': ' 6.57516'}, {'episode': ' 40', ' episode steps': ' 89', ' episode reward': ' 89.000', ' loss': ' 0.364272', ' mean_absolute_error': ' 3.668661', ' mean_q': ' 7.17597'}, {'episode': ' 41', ' episode steps': ' 56', ' episode reward': ' 56.000', ' loss': ' 0.315008', ' mean_absolute_error': ' 3.977457', ' mean_q': ' 7.84599'}, {'episode': ' 42', ' episode steps': ' 46', ' episode reward': ' 46.000', ' loss': ' 0.265045', ' mean_absolute_error': ' 4.197290', ' mean_q': ' 8.34503'}, {'episode': ' 43', ' episode steps': ' 27', ' episode reward': ' 27.000', ' loss': ' 0.336632', ' mean_absolute_error': ' 4.344253', ' mean_q': ' 8.65842'}, {'episode': ' 44', ' episode steps': ' 118', ' episode reward': ' 118.000', ' loss': ' 0.358444', ' mean_absolute_error': ' 4.652878', ' mean_q': ' 9.23385'}, {'episode': ' 45', ' episode steps': ' 36', ' episode reward': ' 36.000', ' loss': ' 0.273760', ' mean_absolute_error': ' 5.033281', ' mean_q': ' 10.1051'}, {'episode': ' 46', ' episode steps': ' 82', ' episode reward': ' 82.000', ' loss': ' 0.373407', ' mean_absolute_error': ' 5.276927', ' mean_q': ' 10.5745'}, {'episode': ' 47', ' episode steps': ' 87', ' episode reward': ' 87.000', ' loss': ' 0.440016', ' mean_absolute_error': ' 5.681759', ' mean_q': ' 11.4207'}, {'episode': ' 48', ' episode steps': ' 136', ' episode reward': ' 136.000', ' loss': ' 0.348960', ' mean_absolute_error': ' 6.169487', ' mean_q': ' 12.4848'}, {'episode': ' 49', ' episode steps': ' 139', ' episode reward': ' 139.000', ' loss': ' 0.555011', ' mean_absolute_error': ' 6.824183', ' mean_q': ' 13.7551'}, {'episode': ' 50', ' episode steps': ' 80', ' episode reward': ' 80.000', ' loss': ' 0.708785', ' mean_absolute_error': ' 7.359047', ' mean_q': ' 14.8363'}, {'episode': ' 51', ' episode steps': ' 190', ' episode reward': ' 190.000', ' loss': ' 0.902548', ' mean_absolute_error': ' 7.952768', ' mean_q': ' 16.0400'}, {'episode': ' 52', ' episode steps': ' 115', ' episode reward': ' 115.000', ' loss': ' 0.943667', ' mean_absolute_error': ' 8.719868', ' mean_q': ' 17.5999'}, {'episode': ' 53', ' episode steps': ' 98', ' episode reward': ' 98.000', ' loss': ' 0.656707', ' mean_absolute_error': ' 9.190284', ' mean_q': ' 18.6482'}, {'episode': ' 54', ' episode steps': ' 117', ' episode reward': ' 117.000', ' loss': ' 1.004947', ' mean_absolute_error': ' 9.720198', ' mean_q': ' 19.6631'}, {'episode': ' 55', ' episode steps': ' 110', ' episode reward': ' 110.000', ' loss': ' 0.985152', ' mean_absolute_error': ' 10.169116', ' mean_q': ' 20.5412'}, {'episode': ' 56', ' episode steps': ' 86', ' episode reward': ' 86.000', ' loss': ' 1.342366', ' mean_absolute_error': ' 10.608091', ' mean_q': ' 21.3900'}, {'episode': ' 57', ' episode steps': ' 126', ' episode reward': ' 126.000', ' loss': ' 1.244294', ' mean_absolute_error': ' 11.023990', ' mean_q': ' 22.2563'}, {'episode': ' 58', ' episode steps': ' 110', ' episode reward': ' 110.000', ' loss': ' 1.042155', ' mean_absolute_error': ' 11.492437', ' mean_q': ' 23.2837'}, {'episode': ' 59', ' episode steps': ' 267', ' episode reward': ' 267.000', ' loss': ' 1.176041', ' mean_absolute_error': ' 12.356016', ' mean_q': ' 25.0568'}, {'episode': ' 60', ' episode steps': ' 123', ' episode reward': ' 123.000', ' loss': ' 1.065391', ' mean_absolute_error': ' 13.312965', ' mean_q': ' 27.0549'}, {'episode': ' 61', ' episode steps': ' 113', ' episode reward': ' 113.000', ' loss': ' 0.972392', ' mean_absolute_error': ' 13.747091', ' mean_q': ' 28.0040'}, {'episode': ' 62', ' episode steps': ' 113', ' episode reward': ' 113.000', ' loss': ' 1.314061', ' mean_absolute_error': ' 14.269607', ' mean_q': ' 28.9844'}, {'episode': ' 63', ' episode steps': ' 121', ' episode reward': ' 121.000', ' loss': ' 1.246324', ' mean_absolute_error': ' 14.765546', ' mean_q': ' 30.0331'}, {'episode': ' 64', ' episode steps': ' 120', ' episode reward': ' 120.000', ' loss': ' 1.543824', ' mean_absolute_error': ' 15.349784', ' mean_q': ' 31.2055'}, {'episode': ' 65', ' episode steps': ' 116', ' episode reward': ' 116.000', ' loss': ' 0.965880', ' mean_absolute_error': ' 15.673398', ' mean_q': ' 31.9415'}, {'episode': ' 66', ' episode steps': ' 131', ' episode reward': ' 131.000', ' loss': ' 1.647946', ' mean_absolute_error': ' 16.283972', ' mean_q': ' 33.0666'}, {'episode': ' 67', ' episode steps': ' 129', ' episode reward': ' 129.000', ' loss': ' 1.891711', ' mean_absolute_error': ' 16.623253', ' mean_q': ' 33.8136'}, {'episode': ' 68', ' episode steps': ' 141', ' episode reward': ' 141.000', ' loss': ' 1.241396', ' mean_absolute_error': ' 17.185675', ' mean_q': ' 34.9497'}, {'episode': ' 69', ' episode steps': ' 123', ' episode reward': ' 123.000', ' loss': ' 1.240435', ' mean_absolute_error': ' 17.764503', ' mean_q': ' 36.1973'}, {'episode': ' 70', ' episode steps': ' 151', ' episode reward': ' 151.000', ' loss': ' 1.568701', ' mean_absolute_error': ' 18.466053', ' mean_q': ' 37.5305'}, {'episode': ' 71', ' episode steps': ' 152', ' episode reward': ' 152.000', ' loss': ' 1.594927', ' mean_absolute_error': ' 18.979239', ' mean_q': ' 38.5899'}, {'episode': ' 72', ' episode steps': ' 166', ' episode reward': ' 166.000', ' loss': ' 1.363492', ' mean_absolute_error': ' 19.447481', ' mean_q': ' 39.5641'}, {'episode': ' 73', ' episode steps': ' 122', ' episode reward': ' 122.000', ' loss': ' 1.587888', ' mean_absolute_error': ' 20.125023', ' mean_q': ' 40.8670'}, {'episode': ' 74', ' episode steps': ' 164', ' episode reward': ' 164.000', ' loss': ' 1.735828', ' mean_absolute_error': ' 20.517803', ' mean_q': ' 41.7825'}, {'episode': ' 75', ' episode steps': ' 146', ' episode reward': ' 146.000', ' loss': ' 1.342584', ' mean_absolute_error': ' 21.058399', ' mean_q': ' 42.8854'}, {'episode': ' 76', ' episode steps': ' 224', ' episode reward': ' 224.000', ' loss': ' 1.706175', ' mean_absolute_error': ' 21.851994', ' mean_q': ' 44.2993'}, {'episode': ' 77', ' episode steps': ' 130', ' episode reward': ' 130.000', ' loss': ' 1.523257', ' mean_absolute_error': ' 22.428846', ' mean_q': ' 45.5532'}, {'episode': ' 78', ' episode steps': ' 199', ' episode reward': ' 199.000', ' loss': ' 1.798136', ' mean_absolute_error': ' 22.932577', ' mean_q': ' 46.6122'}, {'episode': ' 79', ' episode steps': ' 171', ' episode reward': ' 171.000', ' loss': ' 1.627858', ' mean_absolute_error': ' 23.427000', ' mean_q': ' 47.6519'}, {'episode': ' 80', ' episode steps': ' 152', ' episode reward': ' 152.000', ' loss': ' 1.927983', ' mean_absolute_error': ' 24.042112', ' mean_q': ' 48.8055'}, {'episode': ' 81', ' episode steps': ' 183', ' episode reward': ' 183.000', ' loss': ' 2.003144', ' mean_absolute_error': ' 24.682772', ' mean_q': ' 50.1215'}, {'episode': ' 82', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.027018', ' mean_absolute_error': ' 24.997238', ' mean_q': ' 50.7351'}, {'episode': ' 83', ' episode steps': ' 177', ' episode reward': ' 177.000', ' loss': ' 2.397092', ' mean_absolute_error': ' 25.481846', ' mean_q': ' 51.7017'}, {'episode': ' 84', ' episode steps': ' 180', ' episode reward': ' 180.000', ' loss': ' 1.726510', ' mean_absolute_error': ' 26.055420', ' mean_q': ' 52.9556'}, {'episode': ' 85', ' episode steps': ' 268', ' episode reward': ' 268.000', ' loss': ' 1.677988', ' mean_absolute_error': ' 26.722757', ' mean_q': ' 54.2789'}, {'episode': ' 86', ' episode steps': ' 189', ' episode reward': ' 189.000', ' loss': ' 1.744531', ' mean_absolute_error': ' 27.568590', ' mean_q': ' 56.0065'}, {'episode': ' 87', ' episode steps': ' 179', ' episode reward': ' 179.000', ' loss': ' 1.989020', ' mean_absolute_error': ' 27.918995', ' mean_q': ' 56.6397'}, {'episode': ' 88', ' episode steps': ' 167', ' episode reward': ' 167.000', ' loss': ' 2.377820', ' mean_absolute_error': ' 28.328569', ' mean_q': ' 57.3437'}, {'episode': ' 89', ' episode steps': ' 206', ' episode reward': ' 206.000', ' loss': ' 2.063432', ' mean_absolute_error': ' 28.945963', ' mean_q': ' 58.7209'}, {'episode': ' 90', ' episode steps': ' 144', ' episode reward': ' 144.000', ' loss': ' 2.174310', ' mean_absolute_error': ' 29.349663', ' mean_q': ' 59.5136'}, {'episode': ' 91', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.551449', ' mean_absolute_error': ' 29.897852', ' mean_q': ' 60.4940'}, {'episode': ' 92', ' episode steps': ' 210', ' episode reward': ' 210.000', ' loss': ' 2.263921', ' mean_absolute_error': ' 30.214550', ' mean_q': ' 61.2019'}, {'episode': ' 93', ' episode steps': ' 157', ' episode reward': ' 157.000', ' loss': ' 2.099911', ' mean_absolute_error': ' 30.570278', ' mean_q': ' 61.9973'}, {'episode': ' 94', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.580698', ' mean_absolute_error': ' 31.013582', ' mean_q': ' 62.9634'}, {'episode': ' 95', ' episode steps': ' 269', ' episode reward': ' 269.000', ' loss': ' 3.365029', ' mean_absolute_error': ' 31.587200', ' mean_q': ' 64.0880'}, {'episode': ' 96', ' episode steps': ' 229', ' episode reward': ' 229.000', ' loss': ' 2.531268', ' mean_absolute_error': ' 32.363853', ' mean_q': ' 65.6587'}, {'episode': ' 97', ' episode steps': ' 163', ' episode reward': ' 163.000', ' loss': ' 3.215895', ' mean_absolute_error': ' 32.699547', ' mean_q': ' 66.2439'}, {'episode': ' 98', ' episode steps': ' 224', ' episode reward': ' 224.000', ' loss': ' 2.673188', ' mean_absolute_error': ' 33.406178', ' mean_q': ' 67.6555'}, {'episode': ' 99', ' episode steps': ' 240', ' episode reward': ' 240.000', ' loss': ' 3.707894', ' mean_absolute_error': ' 33.718098', ' mean_q': ' 68.3397'}, {'episode': ' 100', ' episode steps': ' 155', ' episode reward': ' 155.000', ' loss': ' 2.967485', ' mean_absolute_error': ' 34.170456', ' mean_q': ' 69.3821'}, {'episode': ' 101', ' episode steps': ' 171', ' episode reward': ' 171.000', ' loss': ' 4.259010', ' mean_absolute_error': ' 34.722195', ' mean_q': ' 70.2244'}, {'episode': ' 102', ' episode steps': ' 193', ' episode reward': ' 193.000', ' loss': ' 3.226599', ' mean_absolute_error': ' 34.913147', ' mean_q': ' 70.6806'}, {'episode': ' 103', ' episode steps': ' 207', ' episode reward': ' 207.000', ' loss': ' 2.782929', ' mean_absolute_error': ' 35.428909', ' mean_q': ' 71.8113'}, {'episode': ' 104', ' episode steps': ' 452', ' episode reward': ' 452.000', ' loss': ' 3.203374', ' mean_absolute_error': ' 36.197533', ' mean_q': ' 73.2415'}, {'episode': ' 105', ' episode steps': ' 220', ' episode reward': ' 220.000', ' loss': ' 3.822625', ' mean_absolute_error': ' 37.098331', ' mean_q': ' 75.0232'}, {'episode': ' 106', ' episode steps': ' 186', ' episode reward': ' 186.000', ' loss': ' 4.236228', ' mean_absolute_error': ' 37.428974', ' mean_q': ' 75.6866'}, {'episode': ' 107', ' episode steps': ' 298', ' episode reward': ' 298.000', ' loss': ' 3.213909', ' mean_absolute_error': ' 37.960251', ' mean_q': ' 76.8512'}, {'episode': ' 108', ' episode steps': ' 295', ' episode reward': ' 295.000', ' loss': ' 4.313341', ' mean_absolute_error': ' 38.760372', ' mean_q': ' 78.3960'}, {'episode': ' 109', ' episode steps': ' 320', ' episode reward': ' 320.000', ' loss': ' 4.328205', ' mean_absolute_error': ' 39.918327', ' mean_q': ' 80.6513'}, {'episode': ' 110', ' episode steps': ' 210', ' episode reward': ' 210.000', ' loss': ' 5.033235', ' mean_absolute_error': ' 40.775799', ' mean_q': ' 82.5969'}, {'episode': ' 111', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 4.987158', ' mean_absolute_error': ' 41.481129', ' mean_q': ' 83.8623'}, {'episode': ' 112', ' episode steps': ' 258', ' episode reward': ' 258.000', ' loss': ' 4.505596', ' mean_absolute_error': ' 42.670341', ' mean_q': ' 86.2613'}, {'episode': ' 113', ' episode steps': ' 318', ' episode reward': ' 318.000', ' loss': ' 7.236184', ' mean_absolute_error': ' 43.157227', ' mean_q': ' 87.1136'}, {'episode': ' 114', ' episode steps': ' 403', ' episode reward': ' 403.000', ' loss': ' 7.445703', ' mean_absolute_error': ' 44.356007', ' mean_q': ' 89.4873'}, {'episode': ' 115', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 6.375701', ' mean_absolute_error': ' 45.284046', ' mean_q': ' 91.5489'}, {'episode': ' 116', ' episode steps': ' 343', ' episode reward': ' 343.000', ' loss': ' 4.630236', ' mean_absolute_error': ' 46.188232', ' mean_q': ' 93.4047'}, {'episode': ' 117', ' episode steps': ' 397', ' episode reward': ' 397.000', ' loss': ' 8.179825', ' mean_absolute_error': ' 47.240070', ' mean_q': ' 95.3232'}, {'episode': ' 118', ' episode steps': ' 492', ' episode reward': ' 492.000', ' loss': ' 7.857806', ' mean_absolute_error': ' 48.487820', ' mean_q': ' 97.8779'}, {'episode': ' 119', ' episode steps': ' 468', ' episode reward': ' 468.000', ' loss': ' 5.364316', ' mean_absolute_error': ' 49.516373', ' mean_q': ' 100.135'}, {'episode': ' 120', ' episode steps': ' 432', ' episode reward': ' 432.000', ' loss': ' 5.347921', ' mean_absolute_error': ' 50.844429', ' mean_q': ' 102.674'}, {'episode': ' 121', ' episode steps': ' 418', ' episode reward': ' 418.000', ' loss': ' 6.581341', ' mean_absolute_error': ' 51.713779', ' mean_q': ' 104.452'}, {'episode': ' 122', ' episode steps': ' 354', ' episode reward': ' 354.000', ' loss': ' 5.236181', ' mean_absolute_error': ' 52.439678', ' mean_q': ' 105.930'}, {'episode': ' 123', ' episode steps': ' 434', ' episode reward': ' 434.000', ' loss': ' 6.352950', ' mean_absolute_error': ' 53.019524', ' mean_q': ' 107.166'}, {'episode': ' 124', ' episode steps': ' 405', ' episode reward': ' 405.000', ' loss': ' 4.551521', ' mean_absolute_error': ' 53.598457', ' mean_q': ' 108.307'}, {'episode': ' 125', ' episode steps': ' 436', ' episode reward': ' 436.000', ' loss': ' 6.172012', ' mean_absolute_error': ' 54.385689', ' mean_q': ' 109.766'}, {'episode': ' 126', ' episode steps': ' 392', ' episode reward': ' 392.000', ' loss': ' 6.755196', ' mean_absolute_error': ' 55.021725', ' mean_q': ' 111.180'}, {'episode': ' 127', ' episode steps': ' 404', ' episode reward': ' 404.000', ' loss': ' 5.070217', ' mean_absolute_error': ' 55.589737', ' mean_q': ' 112.352'}, {'episode': ' 128', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 5.983955', ' mean_absolute_error': ' 56.272701', ' mean_q': ' 113.623'}, {'episode': ' 129', ' episode steps': ' 364', ' episode reward': ' 364.000', ' loss': ' 4.174394', ' mean_absolute_error': ' 56.506268', ' mean_q': ' 114.232'}, {'episode': ' 130', ' episode steps': ' 378', ' episode reward': ' 378.000', ' loss': ' 6.078301', ' mean_absolute_error': ' 57.095238', ' mean_q': ' 115.296'}, {'episode': ' 131', ' episode steps': ' 467', ' episode reward': ' 467.000', ' loss': ' 6.669725', ' mean_absolute_error': ' 57.707584', ' mean_q': ' 116.485'}, {'episode': ' 132', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.729326', ' mean_absolute_error': ' 57.635071', ' mean_q': ' 116.442'}, {'episode': ' 133', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.036013', ' mean_absolute_error': ' 57.700920', ' mean_q': ' 116.663'}, {'episode': ' 134', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 7.369270', ' mean_absolute_error': ' 57.960995', ' mean_q': ' 116.887'}, {'episode': ' 135', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.936100', ' mean_absolute_error': ' 58.215260', ' mean_q': ' 117.580'}, {'episode': ' 136', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.809545', ' mean_absolute_error': ' 57.976994', ' mean_q': ' 117.284'}, {'episode': ' 137', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.790256', ' mean_absolute_error': ' 58.269463', ' mean_q': ' 117.938'}, {'episode': ' 138', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.667628', ' mean_absolute_error': ' 58.719551', ' mean_q': ' 118.687'}, {'episode': ' 139', ' episode steps': ' 399', ' episode reward': ' 399.000', ' loss': ' 4.916703', ' mean_absolute_error': ' 58.614105', ' mean_q': ' 118.458'}, {'episode': ' 140', ' episode steps': ' 374', ' episode reward': ' 374.000', ' loss': ' 5.747376', ' mean_absolute_error': ' 58.734531', ' mean_q': ' 118.635'}, {'episode': ' 141', ' episode steps': ' 427', ' episode reward': ' 427.000', ' loss': ' 6.808571', ' mean_absolute_error': ' 58.877945', ' mean_q': ' 118.775'}, {'episode': ' 142', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.243455', ' mean_absolute_error': ' 59.070789', ' mean_q': ' 119.302'}, {'episode': ' 143', ' episode steps': ' 316', ' episode reward': ' 316.000', ' loss': ' 4.474892', ' mean_absolute_error': ' 58.989685', ' mean_q': ' 118.927'}, {'episode': ' 144', ' episode steps': ' 393', ' episode reward': ' 393.000', ' loss': ' 6.173388', ' mean_absolute_error': ' 59.190575', ' mean_q': ' 119.201'}, {'episode': ' 145', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 5.465988', ' mean_absolute_error': ' 59.256191', ' mean_q': ' 119.247'}, {'episode': ' 146', ' episode steps': ' 438', ' episode reward': ' 438.000', ' loss': ' 5.538434', ' mean_absolute_error': ' 58.917114', ' mean_q': ' 118.733'}, {'episode': ' 147', ' episode steps': ' 421', ' episode reward': ' 421.000', ' loss': ' 6.000508', ' mean_absolute_error': ' 58.645588', ' mean_q': ' 118.159'}, {'episode': ' 148', ' episode steps': ' 330', ' episode reward': ' 330.000', ' loss': ' 5.634782', ' mean_absolute_error': ' 58.481716', ' mean_q': ' 117.832'}, {'episode': ' 149', ' episode steps': ' 363', ' episode reward': ' 363.000', ' loss': ' 5.063807', ' mean_absolute_error': ' 58.597279', ' mean_q': ' 118.086'}, {'episode': ' 150', ' episode steps': ' 357', ' episode reward': ' 357.000', ' loss': ' 4.889977', ' mean_absolute_error': ' 58.595726', ' mean_q': ' 117.918'}, {'episode': ' 151', ' episode steps': ' 352', ' episode reward': ' 352.000', ' loss': ' 8.003345', ' mean_absolute_error': ' 58.194546', ' mean_q': ' 117.196'}, {'episode': ' 152', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 8.385610', ' mean_absolute_error': ' 57.755154', ' mean_q': ' 116.074'}, {'episode': ' 153', ' episode steps': ' 367', ' episode reward': ' 367.000', ' loss': ' 5.622941', ' mean_absolute_error': ' 57.645180', ' mean_q': ' 116.022'}, {'episode': ' 154', ' episode steps': ' 431', ' episode reward': ' 431.000', ' loss': ' 6.725824', ' mean_absolute_error': ' 57.383301', ' mean_q': ' 115.450'}, {'episode': ' 155', ' episode steps': ' 371', ' episode reward': ' 371.000', ' loss': ' 4.053256', ' mean_absolute_error': ' 56.873894', ' mean_q': ' 114.547'}, {'episode': ' 156', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 3.341397', ' mean_absolute_error': ' 57.095154', ' mean_q': ' 114.918'}, {'episode': ' 157', ' episode steps': ' 346', ' episode reward': ' 346.000', ' loss': ' 4.614096', ' mean_absolute_error': ' 56.782242', ' mean_q': ' 114.377'}, {'episode': ' 158', ' episode steps': ' 458', ' episode reward': ' 458.000', ' loss': ' 7.074708', ' mean_absolute_error': ' 56.650791', ' mean_q': ' 113.871'}, {'episode': ' 159', ' episode steps': ' 356', ' episode reward': ' 356.000', ' loss': ' 7.149241', ' mean_absolute_error': ' 56.349609', ' mean_q': ' 113.276'}, {'episode': ' 160', ' episode steps': ' 427', ' episode reward': ' 427.000', ' loss': ' 5.580923', ' mean_absolute_error': ' 56.293774', ' mean_q': ' 113.200'}, {'episode': ' 161', ' episode steps': ' 332', ' episode reward': ' 332.000', ' loss': ' 4.579061', ' mean_absolute_error': ' 56.028416', ' mean_q': ' 112.790'}, {'episode': ' 162', ' episode steps': ' 313', ' episode reward': ' 313.000', ' loss': ' 8.333429', ' mean_absolute_error': ' 55.917332', ' mean_q': ' 112.330'}, {'episode': ' 163', ' episode steps': ' 382', ' episode reward': ' 382.000', ' loss': ' 4.079334', ' mean_absolute_error': ' 55.588089', ' mean_q': ' 112.037'}, {'episode': ' 164', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 5.484010', ' mean_absolute_error': ' 55.531219', ' mean_q': ' 111.644'}, {'episode': ' 165', ' episode steps': ' 431', ' episode reward': ' 431.000', ' loss': ' 7.016966', ' mean_absolute_error': ' 55.541031', ' mean_q': ' 111.580'}, {'episode': ' 166', ' episode steps': ' 341', ' episode reward': ' 341.000', ' loss': ' 7.278677', ' mean_absolute_error': ' 55.330990', ' mean_q': ' 110.998'}, {'episode': ' 167', ' episode steps': ' 398', ' episode reward': ' 398.000', ' loss': ' 7.087126', ' mean_absolute_error': ' 55.133873', ' mean_q': ' 110.779'}, {'episode': ' 168', ' episode steps': ' 471', ' episode reward': ' 471.000', ' loss': ' 6.771763', ' mean_absolute_error': ' 54.837563', ' mean_q': ' 110.228'}, {'episode': ' 169', ' episode steps': ' 496', ' episode reward': ' 496.000', ' loss': ' 7.970106', ' mean_absolute_error': ' 54.635006', ' mean_q': ' 109.722'}, {'episode': ' 170', ' episode steps': ' 491', ' episode reward': ' 491.000', ' loss': ' 5.704204', ' mean_absolute_error': ' 54.260590', ' mean_q': ' 109.047'}, {'episode': ' 171', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 7.200768', ' mean_absolute_error': ' 54.098209', ' mean_q': ' 108.654'}, {'episode': ' 172', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.464919', ' mean_absolute_error': ' 54.360081', ' mean_q': ' 109.216'}, {'episode': ' 173', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.186774', ' mean_absolute_error': ' 53.783821', ' mean_q': ' 108.131'}, {'episode': ' 174', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 4.830243', ' mean_absolute_error': ' 54.135418', ' mean_q': ' 108.937'}, {'episode': ' 175', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 7.292828', ' mean_absolute_error': ' 54.103619', ' mean_q': ' 108.625'}, {'episode': ' 176', ' episode steps': ' 477', ' episode reward': ' 477.000', ' loss': ' 6.350655', ' mean_absolute_error': ' 53.979561', ' mean_q': ' 108.621'}, {'episode': ' 177', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.235330', ' mean_absolute_error': ' 54.053059', ' mean_q': ' 108.718'}, {'episode': ' 178', ' episode steps': ' 499', ' episode reward': ' 499.000', ' loss': ' 5.833961', ' mean_absolute_error': ' 54.018051', ' mean_q': ' 108.660'}, {'episode': ' 179', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.821904', ' mean_absolute_error': ' 54.205986', ' mean_q': ' 109.010'}, {'episode': ' 180', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.201680', ' mean_absolute_error': ' 54.211395', ' mean_q': ' 109.014'}, {'episode': ' 181', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.375962', ' mean_absolute_error': ' 54.281094', ' mean_q': ' 109.005'}, {'episode': ' 182', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.382715', ' mean_absolute_error': ' 54.226540', ' mean_q': ' 108.944'}, {'episode': ' 183', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.900445', ' mean_absolute_error': ' 54.141014', ' mean_q': ' 108.887'}, {'episode': ' 184', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.648526', ' mean_absolute_error': ' 54.440849', ' mean_q': ' 109.243'}, {'episode': ' 185', ' episode steps': ' 440', ' episode reward': ' 440.000', ' loss': ' 4.240374', ' mean_absolute_error': ' 53.966129', ' mean_q': ' 108.517'}, {'episode': ' 186', ' episode steps': ' 327', ' episode reward': ' 327.000', ' loss': ' 2.932429', ' mean_absolute_error': ' 54.022423', ' mean_q': ' 108.469'}, {'episode': ' 187', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.913231', ' mean_absolute_error': ' 53.785702', ' mean_q': ' 108.030'}, {'episode': ' 188', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.370584', ' mean_absolute_error': ' 53.921318', ' mean_q': ' 108.256'}, {'episode': ' 189', ' episode steps': ' 453', ' episode reward': ' 453.000', ' loss': ' 4.394953', ' mean_absolute_error': ' 53.683739', ' mean_q': ' 107.851'}, {'episode': ' 190', ' episode steps': ' 434', ' episode reward': ' 434.000', ' loss': ' 4.740616', ' mean_absolute_error': ' 53.448002', ' mean_q': ' 107.293'}, {'episode': ' 191', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.950387', ' mean_absolute_error': ' 53.467194', ' mean_q': ' 107.309'}, {'episode': ' 192', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 3.836204', ' mean_absolute_error': ' 53.114296', ' mean_q': ' 106.746'}, {'episode': ' 193', ' episode steps': ' 308', ' episode reward': ' 308.000', ' loss': ' 3.644928', ' mean_absolute_error': ' 52.884850', ' mean_q': ' 106.207'}, {'episode': ' 194', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.523789', ' mean_absolute_error': ' 52.529846', ' mean_q': ' 105.522'}, {'episode': ' 195', ' episode steps': ' 345', ' episode reward': ' 345.000', ' loss': ' 5.533070', ' mean_absolute_error': ' 52.417603', ' mean_q': ' 105.200'}, {'episode': ' 196', ' episode steps': ' 250', ' episode reward': ' 250.000', ' loss': ' 3.804307', ' mean_absolute_error': ' 52.173004', ' mean_q': ' 104.850'}, {'episode': ' 197', ' episode steps': ' 398', ' episode reward': ' 398.000', ' loss': ' 4.982242', ' mean_absolute_error': ' 52.211079', ' mean_q': ' 104.764'}, {'episode': ' 198', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.029026', ' mean_absolute_error': ' 52.104034', ' mean_q': ' 104.495'}]\n"
     ]
    }
   ],
   "source": [
    "new_dict = []\n",
    "for line in new_lines:\n",
    "    dict_row = {}\n",
    "    new_line = line.split(\",\")\n",
    "#     print(new_line)\n",
    "    \n",
    "    no = new_line[0].split(\":\")\n",
    "    dict_row[no[0]] = no[1]\n",
    "    \n",
    "    step = new_line[2].split(\":\")\n",
    "    dict_row[step[0]] = step[1]\n",
    "    \n",
    "    reward = new_line[4].split(\":\")\n",
    "    dict_row[reward[0]] = reward[1];\n",
    "    \n",
    "    loss = new_line[11].split(\":\")\n",
    "    dict_row[loss[0]] = loss[1];\n",
    "    \n",
    "    abs_error = new_line[12].split(\":\")\n",
    "    dict_row[abs_error[0]] = abs_error[1];\n",
    "    \n",
    "    q = new_line[13].split(\":\")\n",
    "    dict_row[q[0]] = q[1][:8];\n",
    "    \n",
    "#     print(dict_row)\n",
    "    new_dict.append(dict_row)\n",
    "\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dqn_metrics.csv\", 'w') as f:\n",
    "    fieldnames = ['episode', ' episode steps', ' episode reward', ' loss', ' mean_absolute_error', ' mean_q']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for row in new_dict:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 6 columns):\n",
      "episode                 198 non-null int64\n",
      " episode steps          198 non-null int64\n",
      " episode reward         198 non-null float64\n",
      " loss                   198 non-null float64\n",
      " mean_absolute_error    198 non-null float64\n",
      " mean_q                 198 non-null float64\n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 9.4 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dqn_metrics.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(filename):\n",
    "    try:\n",
    "        with open(filename,'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except: \n",
    "        print(\"No file!\")\n",
    "        return 0\n",
    "        \n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        new_lines.append(line[14:])\n",
    "    \n",
    "    new_dict = []\n",
    "    for line in new_lines:\n",
    "        dict_row = {}\n",
    "        new_line = line.split(\",\")\n",
    "        #print(new_line)\n",
    "\n",
    "        no = new_line[0].split(\":\")\n",
    "        dict_row[no[0]] = no[1]\n",
    "\n",
    "        step = new_line[2].split(\":\")\n",
    "        dict_row[step[0]] = step[1]\n",
    "\n",
    "        reward = new_line[4].split(\":\")\n",
    "        dict_row[reward[0]] = reward[1];\n",
    "\n",
    "        loss = new_line[11].split(\":\")\n",
    "        dict_row[loss[0]] = loss[1];\n",
    "\n",
    "        abs_error = new_line[12].split(\":\")\n",
    "        dict_row[abs_error[0]] = abs_error[1];\n",
    "\n",
    "        q = new_line[13].split(\":\")\n",
    "        dict_row[q[0]] = q[1][:8];\n",
    "\n",
    "        #print(dict_row)\n",
    "        new_dict.append(dict_row)\n",
    "        \n",
    "    with open(filename+\".csv\", 'w') as f:\n",
    "        fieldnames = ['episode', ' episode steps', ' episode reward', ' loss', ' mean_absolute_error', ' mean_q']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in new_dict:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode': ' 1', ' episode steps': ' 31', ' episode reward': ' 31.000', ' loss': ' 0.462173', ' mean_absolute_error': ' 0.520752', ' mean_q': ' 0.09643'}\n",
      "{'episode': ' 2', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.352699', ' mean_absolute_error': ' 0.544416', ' mean_q': ' 0.29091'}\n",
      "{'episode': ' 3', ' episode steps': ' 20', ' episode reward': ' 20.000', ' loss': ' 0.233226', ' mean_absolute_error': ' 0.553622', ' mean_q': ' 0.48196'}\n",
      "{'episode': ' 4', ' episode steps': ' 19', ' episode reward': ' 19.000', ' loss': ' 0.115771', ' mean_absolute_error': ' 0.604906', ' mean_q': ' 0.84110'}\n",
      "{'episode': ' 5', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.060949', ' mean_absolute_error': ' 0.689512', ' mean_q': ' 1.18735'}\n",
      "{'episode': ' 6', ' episode steps': ' 16', ' episode reward': ' 16.000', ' loss': ' 0.041591', ' mean_absolute_error': ' 0.727885', ' mean_q': ' 1.31664'}\n",
      "{'episode': ' 7', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.034899', ' mean_absolute_error': ' 0.761641', ' mean_q': ' 1.43547'}\n",
      "{'episode': ' 8', ' episode steps': ' 23', ' episode reward': ' 23.000', ' loss': ' 0.020848', ' mean_absolute_error': ' 0.825447', ' mean_q': ' 1.62185'}\n",
      "{'episode': ' 9', ' episode steps': ' 11', ' episode reward': ' 11.000', ' loss': ' 0.033472', ' mean_absolute_error': ' 0.876673', ' mean_q': ' 1.74907'}\n",
      "{'episode': ' 10', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.040221', ' mean_absolute_error': ' 0.940421', ' mean_q': ' 1.90073'}\n",
      "{'episode': ' 11', ' episode steps': ' 33', ' episode reward': ' 33.000', ' loss': ' 0.037214', ' mean_absolute_error': ' 0.993950', ' mean_q': ' 2.01666'}\n",
      "{'episode': ' 12', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.049411', ' mean_absolute_error': ' 1.103708', ' mean_q': ' 2.21094'}\n",
      "{'episode': ' 13', ' episode steps': ' 12', ' episode reward': ' 12.000', ' loss': ' 0.055344', ' mean_absolute_error': ' 1.173260', ' mean_q': ' 2.36691'}\n",
      "{'episode': ' 14', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.058532', ' mean_absolute_error': ' 1.220065', ' mean_q': ' 2.46508'}\n",
      "{'episode': ' 15', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.058335', ' mean_absolute_error': ' 1.309274', ' mean_q': ' 2.63785'}\n",
      "{'episode': ' 16', ' episode steps': ' 25', ' episode reward': ' 25.000', ' loss': ' 0.086458', ' mean_absolute_error': ' 1.378768', ' mean_q': ' 2.74835'}\n",
      "{'episode': ' 17', ' episode steps': ' 19', ' episode reward': ' 19.000', ' loss': ' 0.083784', ' mean_absolute_error': ' 1.489895', ' mean_q': ' 2.98567'}\n",
      "{'episode': ' 18', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.130680', ' mean_absolute_error': ' 1.577877', ' mean_q': ' 3.05985'}\n",
      "{'episode': ' 19', ' episode steps': ' 37', ' episode reward': ' 37.000', ' loss': ' 0.128095', ' mean_absolute_error': ' 1.673273', ' mean_q': ' 3.29401'}\n",
      "{'episode': ' 20', ' episode steps': ' 18', ' episode reward': ' 18.000', ' loss': ' 0.150520', ' mean_absolute_error': ' 1.778720', ' mean_q': ' 3.48117'}\n",
      "{'episode': ' 21', ' episode steps': ' 9', ' episode reward': ' 9.000', ' loss': ' 0.160706', ' mean_absolute_error': ' 1.887498', ' mean_q': ' 3.69824'}\n",
      "{'episode': ' 22', ' episode steps': ' 43', ' episode reward': ' 43.000', ' loss': ' 0.146749', ' mean_absolute_error': ' 1.952648', ' mean_q': ' 3.83272'}\n",
      "{'episode': ' 23', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.179906', ' mean_absolute_error': ' 2.075476', ' mean_q': ' 4.12165'}\n",
      "{'episode': ' 24', ' episode steps': ' 16', ' episode reward': ' 16.000', ' loss': ' 0.149710', ' mean_absolute_error': ' 2.145880', ' mean_q': ' 4.20906'}\n",
      "{'episode': ' 25', ' episode steps': ' 24', ' episode reward': ' 24.000', ' loss': ' 0.188366', ' mean_absolute_error': ' 2.244536', ' mean_q': ' 4.42753'}\n",
      "{'episode': ' 26', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.239616', ' mean_absolute_error': ' 2.327628', ' mean_q': ' 4.50919'}\n",
      "{'episode': ' 27', ' episode steps': ' 13', ' episode reward': ' 13.000', ' loss': ' 0.234737', ' mean_absolute_error': ' 2.413644', ' mean_q': ' 4.64805'}\n",
      "{'episode': ' 28', ' episode steps': ' 22', ' episode reward': ' 22.000', ' loss': ' 0.181015', ' mean_absolute_error': ' 2.453977', ' mean_q': ' 4.74760'}\n",
      "{'episode': ' 29', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.192081', ' mean_absolute_error': ' 2.530632', ' mean_q': ' 4.94936'}\n",
      "{'episode': ' 30', ' episode steps': ' 10', ' episode reward': ' 10.000', ' loss': ' 0.299307', ' mean_absolute_error': ' 2.586266', ' mean_q': ' 4.98405'}\n",
      "{'episode': ' 31', ' episode steps': ' 48', ' episode reward': ' 48.000', ' loss': ' 0.223936', ' mean_absolute_error': ' 2.721186', ' mean_q': ' 5.23096'}\n",
      "{'episode': ' 32', ' episode steps': ' 14', ' episode reward': ' 14.000', ' loss': ' 0.222922', ' mean_absolute_error': ' 2.832808', ' mean_q': ' 5.45189'}\n",
      "{'episode': ' 33', ' episode steps': ' 12', ' episode reward': ' 12.000', ' loss': ' 0.280619', ' mean_absolute_error': ' 2.913803', ' mean_q': ' 5.59454'}\n",
      "{'episode': ' 34', ' episode steps': ' 23', ' episode reward': ' 23.000', ' loss': ' 0.238156', ' mean_absolute_error': ' 2.958582', ' mean_q': ' 5.64981'}\n",
      "{'episode': ' 35', ' episode steps': ' 15', ' episode reward': ' 15.000', ' loss': ' 0.282031', ' mean_absolute_error': ' 3.028489', ' mean_q': ' 5.75174'}\n",
      "{'episode': ' 36', ' episode steps': ' 21', ' episode reward': ' 21.000', ' loss': ' 0.211309', ' mean_absolute_error': ' 3.096119', ' mean_q': ' 5.96782'}\n",
      "{'episode': ' 37', ' episode steps': ' 47', ' episode reward': ' 47.000', ' loss': ' 0.269584', ' mean_absolute_error': ' 3.221706', ' mean_q': ' 6.21779'}\n",
      "{'episode': ' 38', ' episode steps': ' 11', ' episode reward': ' 11.000', ' loss': ' 0.222184', ' mean_absolute_error': ' 3.326948', ' mean_q': ' 6.50837'}\n",
      "{'episode': ' 39', ' episode steps': ' 39', ' episode reward': ' 39.000', ' loss': ' 0.298241', ' mean_absolute_error': ' 3.398300', ' mean_q': ' 6.57516'}\n",
      "{'episode': ' 40', ' episode steps': ' 89', ' episode reward': ' 89.000', ' loss': ' 0.364272', ' mean_absolute_error': ' 3.668661', ' mean_q': ' 7.17597'}\n",
      "{'episode': ' 41', ' episode steps': ' 56', ' episode reward': ' 56.000', ' loss': ' 0.315008', ' mean_absolute_error': ' 3.977457', ' mean_q': ' 7.84599'}\n",
      "{'episode': ' 42', ' episode steps': ' 46', ' episode reward': ' 46.000', ' loss': ' 0.265045', ' mean_absolute_error': ' 4.197290', ' mean_q': ' 8.34503'}\n",
      "{'episode': ' 43', ' episode steps': ' 27', ' episode reward': ' 27.000', ' loss': ' 0.336632', ' mean_absolute_error': ' 4.344253', ' mean_q': ' 8.65842'}\n",
      "{'episode': ' 44', ' episode steps': ' 118', ' episode reward': ' 118.000', ' loss': ' 0.358444', ' mean_absolute_error': ' 4.652878', ' mean_q': ' 9.23385'}\n",
      "{'episode': ' 45', ' episode steps': ' 36', ' episode reward': ' 36.000', ' loss': ' 0.273760', ' mean_absolute_error': ' 5.033281', ' mean_q': ' 10.1051'}\n",
      "{'episode': ' 46', ' episode steps': ' 82', ' episode reward': ' 82.000', ' loss': ' 0.373407', ' mean_absolute_error': ' 5.276927', ' mean_q': ' 10.5745'}\n",
      "{'episode': ' 47', ' episode steps': ' 87', ' episode reward': ' 87.000', ' loss': ' 0.440016', ' mean_absolute_error': ' 5.681759', ' mean_q': ' 11.4207'}\n",
      "{'episode': ' 48', ' episode steps': ' 136', ' episode reward': ' 136.000', ' loss': ' 0.348960', ' mean_absolute_error': ' 6.169487', ' mean_q': ' 12.4848'}\n",
      "{'episode': ' 49', ' episode steps': ' 139', ' episode reward': ' 139.000', ' loss': ' 0.555011', ' mean_absolute_error': ' 6.824183', ' mean_q': ' 13.7551'}\n",
      "{'episode': ' 50', ' episode steps': ' 80', ' episode reward': ' 80.000', ' loss': ' 0.708785', ' mean_absolute_error': ' 7.359047', ' mean_q': ' 14.8363'}\n",
      "{'episode': ' 51', ' episode steps': ' 190', ' episode reward': ' 190.000', ' loss': ' 0.902548', ' mean_absolute_error': ' 7.952768', ' mean_q': ' 16.0400'}\n",
      "{'episode': ' 52', ' episode steps': ' 115', ' episode reward': ' 115.000', ' loss': ' 0.943667', ' mean_absolute_error': ' 8.719868', ' mean_q': ' 17.5999'}\n",
      "{'episode': ' 53', ' episode steps': ' 98', ' episode reward': ' 98.000', ' loss': ' 0.656707', ' mean_absolute_error': ' 9.190284', ' mean_q': ' 18.6482'}\n",
      "{'episode': ' 54', ' episode steps': ' 117', ' episode reward': ' 117.000', ' loss': ' 1.004947', ' mean_absolute_error': ' 9.720198', ' mean_q': ' 19.6631'}\n",
      "{'episode': ' 55', ' episode steps': ' 110', ' episode reward': ' 110.000', ' loss': ' 0.985152', ' mean_absolute_error': ' 10.169116', ' mean_q': ' 20.5412'}\n",
      "{'episode': ' 56', ' episode steps': ' 86', ' episode reward': ' 86.000', ' loss': ' 1.342366', ' mean_absolute_error': ' 10.608091', ' mean_q': ' 21.3900'}\n",
      "{'episode': ' 57', ' episode steps': ' 126', ' episode reward': ' 126.000', ' loss': ' 1.244294', ' mean_absolute_error': ' 11.023990', ' mean_q': ' 22.2563'}\n",
      "{'episode': ' 58', ' episode steps': ' 110', ' episode reward': ' 110.000', ' loss': ' 1.042155', ' mean_absolute_error': ' 11.492437', ' mean_q': ' 23.2837'}\n",
      "{'episode': ' 59', ' episode steps': ' 267', ' episode reward': ' 267.000', ' loss': ' 1.176041', ' mean_absolute_error': ' 12.356016', ' mean_q': ' 25.0568'}\n",
      "{'episode': ' 60', ' episode steps': ' 123', ' episode reward': ' 123.000', ' loss': ' 1.065391', ' mean_absolute_error': ' 13.312965', ' mean_q': ' 27.0549'}\n",
      "{'episode': ' 61', ' episode steps': ' 113', ' episode reward': ' 113.000', ' loss': ' 0.972392', ' mean_absolute_error': ' 13.747091', ' mean_q': ' 28.0040'}\n",
      "{'episode': ' 62', ' episode steps': ' 113', ' episode reward': ' 113.000', ' loss': ' 1.314061', ' mean_absolute_error': ' 14.269607', ' mean_q': ' 28.9844'}\n",
      "{'episode': ' 63', ' episode steps': ' 121', ' episode reward': ' 121.000', ' loss': ' 1.246324', ' mean_absolute_error': ' 14.765546', ' mean_q': ' 30.0331'}\n",
      "{'episode': ' 64', ' episode steps': ' 120', ' episode reward': ' 120.000', ' loss': ' 1.543824', ' mean_absolute_error': ' 15.349784', ' mean_q': ' 31.2055'}\n",
      "{'episode': ' 65', ' episode steps': ' 116', ' episode reward': ' 116.000', ' loss': ' 0.965880', ' mean_absolute_error': ' 15.673398', ' mean_q': ' 31.9415'}\n",
      "{'episode': ' 66', ' episode steps': ' 131', ' episode reward': ' 131.000', ' loss': ' 1.647946', ' mean_absolute_error': ' 16.283972', ' mean_q': ' 33.0666'}\n",
      "{'episode': ' 67', ' episode steps': ' 129', ' episode reward': ' 129.000', ' loss': ' 1.891711', ' mean_absolute_error': ' 16.623253', ' mean_q': ' 33.8136'}\n",
      "{'episode': ' 68', ' episode steps': ' 141', ' episode reward': ' 141.000', ' loss': ' 1.241396', ' mean_absolute_error': ' 17.185675', ' mean_q': ' 34.9497'}\n",
      "{'episode': ' 69', ' episode steps': ' 123', ' episode reward': ' 123.000', ' loss': ' 1.240435', ' mean_absolute_error': ' 17.764503', ' mean_q': ' 36.1973'}\n",
      "{'episode': ' 70', ' episode steps': ' 151', ' episode reward': ' 151.000', ' loss': ' 1.568701', ' mean_absolute_error': ' 18.466053', ' mean_q': ' 37.5305'}\n",
      "{'episode': ' 71', ' episode steps': ' 152', ' episode reward': ' 152.000', ' loss': ' 1.594927', ' mean_absolute_error': ' 18.979239', ' mean_q': ' 38.5899'}\n",
      "{'episode': ' 72', ' episode steps': ' 166', ' episode reward': ' 166.000', ' loss': ' 1.363492', ' mean_absolute_error': ' 19.447481', ' mean_q': ' 39.5641'}\n",
      "{'episode': ' 73', ' episode steps': ' 122', ' episode reward': ' 122.000', ' loss': ' 1.587888', ' mean_absolute_error': ' 20.125023', ' mean_q': ' 40.8670'}\n",
      "{'episode': ' 74', ' episode steps': ' 164', ' episode reward': ' 164.000', ' loss': ' 1.735828', ' mean_absolute_error': ' 20.517803', ' mean_q': ' 41.7825'}\n",
      "{'episode': ' 75', ' episode steps': ' 146', ' episode reward': ' 146.000', ' loss': ' 1.342584', ' mean_absolute_error': ' 21.058399', ' mean_q': ' 42.8854'}\n",
      "{'episode': ' 76', ' episode steps': ' 224', ' episode reward': ' 224.000', ' loss': ' 1.706175', ' mean_absolute_error': ' 21.851994', ' mean_q': ' 44.2993'}\n",
      "{'episode': ' 77', ' episode steps': ' 130', ' episode reward': ' 130.000', ' loss': ' 1.523257', ' mean_absolute_error': ' 22.428846', ' mean_q': ' 45.5532'}\n",
      "{'episode': ' 78', ' episode steps': ' 199', ' episode reward': ' 199.000', ' loss': ' 1.798136', ' mean_absolute_error': ' 22.932577', ' mean_q': ' 46.6122'}\n",
      "{'episode': ' 79', ' episode steps': ' 171', ' episode reward': ' 171.000', ' loss': ' 1.627858', ' mean_absolute_error': ' 23.427000', ' mean_q': ' 47.6519'}\n",
      "{'episode': ' 80', ' episode steps': ' 152', ' episode reward': ' 152.000', ' loss': ' 1.927983', ' mean_absolute_error': ' 24.042112', ' mean_q': ' 48.8055'}\n",
      "{'episode': ' 81', ' episode steps': ' 183', ' episode reward': ' 183.000', ' loss': ' 2.003144', ' mean_absolute_error': ' 24.682772', ' mean_q': ' 50.1215'}\n",
      "{'episode': ' 82', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.027018', ' mean_absolute_error': ' 24.997238', ' mean_q': ' 50.7351'}\n",
      "{'episode': ' 83', ' episode steps': ' 177', ' episode reward': ' 177.000', ' loss': ' 2.397092', ' mean_absolute_error': ' 25.481846', ' mean_q': ' 51.7017'}\n",
      "{'episode': ' 84', ' episode steps': ' 180', ' episode reward': ' 180.000', ' loss': ' 1.726510', ' mean_absolute_error': ' 26.055420', ' mean_q': ' 52.9556'}\n",
      "{'episode': ' 85', ' episode steps': ' 268', ' episode reward': ' 268.000', ' loss': ' 1.677988', ' mean_absolute_error': ' 26.722757', ' mean_q': ' 54.2789'}\n",
      "{'episode': ' 86', ' episode steps': ' 189', ' episode reward': ' 189.000', ' loss': ' 1.744531', ' mean_absolute_error': ' 27.568590', ' mean_q': ' 56.0065'}\n",
      "{'episode': ' 87', ' episode steps': ' 179', ' episode reward': ' 179.000', ' loss': ' 1.989020', ' mean_absolute_error': ' 27.918995', ' mean_q': ' 56.6397'}\n",
      "{'episode': ' 88', ' episode steps': ' 167', ' episode reward': ' 167.000', ' loss': ' 2.377820', ' mean_absolute_error': ' 28.328569', ' mean_q': ' 57.3437'}\n",
      "{'episode': ' 89', ' episode steps': ' 206', ' episode reward': ' 206.000', ' loss': ' 2.063432', ' mean_absolute_error': ' 28.945963', ' mean_q': ' 58.7209'}\n",
      "{'episode': ' 90', ' episode steps': ' 144', ' episode reward': ' 144.000', ' loss': ' 2.174310', ' mean_absolute_error': ' 29.349663', ' mean_q': ' 59.5136'}\n",
      "{'episode': ' 91', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.551449', ' mean_absolute_error': ' 29.897852', ' mean_q': ' 60.4940'}\n",
      "{'episode': ' 92', ' episode steps': ' 210', ' episode reward': ' 210.000', ' loss': ' 2.263921', ' mean_absolute_error': ' 30.214550', ' mean_q': ' 61.2019'}\n",
      "{'episode': ' 93', ' episode steps': ' 157', ' episode reward': ' 157.000', ' loss': ' 2.099911', ' mean_absolute_error': ' 30.570278', ' mean_q': ' 61.9973'}\n",
      "{'episode': ' 94', ' episode steps': ' 174', ' episode reward': ' 174.000', ' loss': ' 2.580698', ' mean_absolute_error': ' 31.013582', ' mean_q': ' 62.9634'}\n",
      "{'episode': ' 95', ' episode steps': ' 269', ' episode reward': ' 269.000', ' loss': ' 3.365029', ' mean_absolute_error': ' 31.587200', ' mean_q': ' 64.0880'}\n",
      "{'episode': ' 96', ' episode steps': ' 229', ' episode reward': ' 229.000', ' loss': ' 2.531268', ' mean_absolute_error': ' 32.363853', ' mean_q': ' 65.6587'}\n",
      "{'episode': ' 97', ' episode steps': ' 163', ' episode reward': ' 163.000', ' loss': ' 3.215895', ' mean_absolute_error': ' 32.699547', ' mean_q': ' 66.2439'}\n",
      "{'episode': ' 98', ' episode steps': ' 224', ' episode reward': ' 224.000', ' loss': ' 2.673188', ' mean_absolute_error': ' 33.406178', ' mean_q': ' 67.6555'}\n",
      "{'episode': ' 99', ' episode steps': ' 240', ' episode reward': ' 240.000', ' loss': ' 3.707894', ' mean_absolute_error': ' 33.718098', ' mean_q': ' 68.3397'}\n",
      "{'episode': ' 100', ' episode steps': ' 155', ' episode reward': ' 155.000', ' loss': ' 2.967485', ' mean_absolute_error': ' 34.170456', ' mean_q': ' 69.3821'}\n",
      "{'episode': ' 101', ' episode steps': ' 171', ' episode reward': ' 171.000', ' loss': ' 4.259010', ' mean_absolute_error': ' 34.722195', ' mean_q': ' 70.2244'}\n",
      "{'episode': ' 102', ' episode steps': ' 193', ' episode reward': ' 193.000', ' loss': ' 3.226599', ' mean_absolute_error': ' 34.913147', ' mean_q': ' 70.6806'}\n",
      "{'episode': ' 103', ' episode steps': ' 207', ' episode reward': ' 207.000', ' loss': ' 2.782929', ' mean_absolute_error': ' 35.428909', ' mean_q': ' 71.8113'}\n",
      "{'episode': ' 104', ' episode steps': ' 452', ' episode reward': ' 452.000', ' loss': ' 3.203374', ' mean_absolute_error': ' 36.197533', ' mean_q': ' 73.2415'}\n",
      "{'episode': ' 105', ' episode steps': ' 220', ' episode reward': ' 220.000', ' loss': ' 3.822625', ' mean_absolute_error': ' 37.098331', ' mean_q': ' 75.0232'}\n",
      "{'episode': ' 106', ' episode steps': ' 186', ' episode reward': ' 186.000', ' loss': ' 4.236228', ' mean_absolute_error': ' 37.428974', ' mean_q': ' 75.6866'}\n",
      "{'episode': ' 107', ' episode steps': ' 298', ' episode reward': ' 298.000', ' loss': ' 3.213909', ' mean_absolute_error': ' 37.960251', ' mean_q': ' 76.8512'}\n",
      "{'episode': ' 108', ' episode steps': ' 295', ' episode reward': ' 295.000', ' loss': ' 4.313341', ' mean_absolute_error': ' 38.760372', ' mean_q': ' 78.3960'}\n",
      "{'episode': ' 109', ' episode steps': ' 320', ' episode reward': ' 320.000', ' loss': ' 4.328205', ' mean_absolute_error': ' 39.918327', ' mean_q': ' 80.6513'}\n",
      "{'episode': ' 110', ' episode steps': ' 210', ' episode reward': ' 210.000', ' loss': ' 5.033235', ' mean_absolute_error': ' 40.775799', ' mean_q': ' 82.5969'}\n",
      "{'episode': ' 111', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 4.987158', ' mean_absolute_error': ' 41.481129', ' mean_q': ' 83.8623'}\n",
      "{'episode': ' 112', ' episode steps': ' 258', ' episode reward': ' 258.000', ' loss': ' 4.505596', ' mean_absolute_error': ' 42.670341', ' mean_q': ' 86.2613'}\n",
      "{'episode': ' 113', ' episode steps': ' 318', ' episode reward': ' 318.000', ' loss': ' 7.236184', ' mean_absolute_error': ' 43.157227', ' mean_q': ' 87.1136'}\n",
      "{'episode': ' 114', ' episode steps': ' 403', ' episode reward': ' 403.000', ' loss': ' 7.445703', ' mean_absolute_error': ' 44.356007', ' mean_q': ' 89.4873'}\n",
      "{'episode': ' 115', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 6.375701', ' mean_absolute_error': ' 45.284046', ' mean_q': ' 91.5489'}\n",
      "{'episode': ' 116', ' episode steps': ' 343', ' episode reward': ' 343.000', ' loss': ' 4.630236', ' mean_absolute_error': ' 46.188232', ' mean_q': ' 93.4047'}\n",
      "{'episode': ' 117', ' episode steps': ' 397', ' episode reward': ' 397.000', ' loss': ' 8.179825', ' mean_absolute_error': ' 47.240070', ' mean_q': ' 95.3232'}\n",
      "{'episode': ' 118', ' episode steps': ' 492', ' episode reward': ' 492.000', ' loss': ' 7.857806', ' mean_absolute_error': ' 48.487820', ' mean_q': ' 97.8779'}\n",
      "{'episode': ' 119', ' episode steps': ' 468', ' episode reward': ' 468.000', ' loss': ' 5.364316', ' mean_absolute_error': ' 49.516373', ' mean_q': ' 100.135'}\n",
      "{'episode': ' 120', ' episode steps': ' 432', ' episode reward': ' 432.000', ' loss': ' 5.347921', ' mean_absolute_error': ' 50.844429', ' mean_q': ' 102.674'}\n",
      "{'episode': ' 121', ' episode steps': ' 418', ' episode reward': ' 418.000', ' loss': ' 6.581341', ' mean_absolute_error': ' 51.713779', ' mean_q': ' 104.452'}\n",
      "{'episode': ' 122', ' episode steps': ' 354', ' episode reward': ' 354.000', ' loss': ' 5.236181', ' mean_absolute_error': ' 52.439678', ' mean_q': ' 105.930'}\n",
      "{'episode': ' 123', ' episode steps': ' 434', ' episode reward': ' 434.000', ' loss': ' 6.352950', ' mean_absolute_error': ' 53.019524', ' mean_q': ' 107.166'}\n",
      "{'episode': ' 124', ' episode steps': ' 405', ' episode reward': ' 405.000', ' loss': ' 4.551521', ' mean_absolute_error': ' 53.598457', ' mean_q': ' 108.307'}\n",
      "{'episode': ' 125', ' episode steps': ' 436', ' episode reward': ' 436.000', ' loss': ' 6.172012', ' mean_absolute_error': ' 54.385689', ' mean_q': ' 109.766'}\n",
      "{'episode': ' 126', ' episode steps': ' 392', ' episode reward': ' 392.000', ' loss': ' 6.755196', ' mean_absolute_error': ' 55.021725', ' mean_q': ' 111.180'}\n",
      "{'episode': ' 127', ' episode steps': ' 404', ' episode reward': ' 404.000', ' loss': ' 5.070217', ' mean_absolute_error': ' 55.589737', ' mean_q': ' 112.352'}\n",
      "{'episode': ' 128', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 5.983955', ' mean_absolute_error': ' 56.272701', ' mean_q': ' 113.623'}\n",
      "{'episode': ' 129', ' episode steps': ' 364', ' episode reward': ' 364.000', ' loss': ' 4.174394', ' mean_absolute_error': ' 56.506268', ' mean_q': ' 114.232'}\n",
      "{'episode': ' 130', ' episode steps': ' 378', ' episode reward': ' 378.000', ' loss': ' 6.078301', ' mean_absolute_error': ' 57.095238', ' mean_q': ' 115.296'}\n",
      "{'episode': ' 131', ' episode steps': ' 467', ' episode reward': ' 467.000', ' loss': ' 6.669725', ' mean_absolute_error': ' 57.707584', ' mean_q': ' 116.485'}\n",
      "{'episode': ' 132', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.729326', ' mean_absolute_error': ' 57.635071', ' mean_q': ' 116.442'}\n",
      "{'episode': ' 133', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.036013', ' mean_absolute_error': ' 57.700920', ' mean_q': ' 116.663'}\n",
      "{'episode': ' 134', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 7.369270', ' mean_absolute_error': ' 57.960995', ' mean_q': ' 116.887'}\n",
      "{'episode': ' 135', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.936100', ' mean_absolute_error': ' 58.215260', ' mean_q': ' 117.580'}\n",
      "{'episode': ' 136', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.809545', ' mean_absolute_error': ' 57.976994', ' mean_q': ' 117.284'}\n",
      "{'episode': ' 137', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.790256', ' mean_absolute_error': ' 58.269463', ' mean_q': ' 117.938'}\n",
      "{'episode': ' 138', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.667628', ' mean_absolute_error': ' 58.719551', ' mean_q': ' 118.687'}\n",
      "{'episode': ' 139', ' episode steps': ' 399', ' episode reward': ' 399.000', ' loss': ' 4.916703', ' mean_absolute_error': ' 58.614105', ' mean_q': ' 118.458'}\n",
      "{'episode': ' 140', ' episode steps': ' 374', ' episode reward': ' 374.000', ' loss': ' 5.747376', ' mean_absolute_error': ' 58.734531', ' mean_q': ' 118.635'}\n",
      "{'episode': ' 141', ' episode steps': ' 427', ' episode reward': ' 427.000', ' loss': ' 6.808571', ' mean_absolute_error': ' 58.877945', ' mean_q': ' 118.775'}\n",
      "{'episode': ' 142', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.243455', ' mean_absolute_error': ' 59.070789', ' mean_q': ' 119.302'}\n",
      "{'episode': ' 143', ' episode steps': ' 316', ' episode reward': ' 316.000', ' loss': ' 4.474892', ' mean_absolute_error': ' 58.989685', ' mean_q': ' 118.927'}\n",
      "{'episode': ' 144', ' episode steps': ' 393', ' episode reward': ' 393.000', ' loss': ' 6.173388', ' mean_absolute_error': ' 59.190575', ' mean_q': ' 119.201'}\n",
      "{'episode': ' 145', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 5.465988', ' mean_absolute_error': ' 59.256191', ' mean_q': ' 119.247'}\n",
      "{'episode': ' 146', ' episode steps': ' 438', ' episode reward': ' 438.000', ' loss': ' 5.538434', ' mean_absolute_error': ' 58.917114', ' mean_q': ' 118.733'}\n",
      "{'episode': ' 147', ' episode steps': ' 421', ' episode reward': ' 421.000', ' loss': ' 6.000508', ' mean_absolute_error': ' 58.645588', ' mean_q': ' 118.159'}\n",
      "{'episode': ' 148', ' episode steps': ' 330', ' episode reward': ' 330.000', ' loss': ' 5.634782', ' mean_absolute_error': ' 58.481716', ' mean_q': ' 117.832'}\n",
      "{'episode': ' 149', ' episode steps': ' 363', ' episode reward': ' 363.000', ' loss': ' 5.063807', ' mean_absolute_error': ' 58.597279', ' mean_q': ' 118.086'}\n",
      "{'episode': ' 150', ' episode steps': ' 357', ' episode reward': ' 357.000', ' loss': ' 4.889977', ' mean_absolute_error': ' 58.595726', ' mean_q': ' 117.918'}\n",
      "{'episode': ' 151', ' episode steps': ' 352', ' episode reward': ' 352.000', ' loss': ' 8.003345', ' mean_absolute_error': ' 58.194546', ' mean_q': ' 117.196'}\n",
      "{'episode': ' 152', ' episode steps': ' 416', ' episode reward': ' 416.000', ' loss': ' 8.385610', ' mean_absolute_error': ' 57.755154', ' mean_q': ' 116.074'}\n",
      "{'episode': ' 153', ' episode steps': ' 367', ' episode reward': ' 367.000', ' loss': ' 5.622941', ' mean_absolute_error': ' 57.645180', ' mean_q': ' 116.022'}\n",
      "{'episode': ' 154', ' episode steps': ' 431', ' episode reward': ' 431.000', ' loss': ' 6.725824', ' mean_absolute_error': ' 57.383301', ' mean_q': ' 115.450'}\n",
      "{'episode': ' 155', ' episode steps': ' 371', ' episode reward': ' 371.000', ' loss': ' 4.053256', ' mean_absolute_error': ' 56.873894', ' mean_q': ' 114.547'}\n",
      "{'episode': ' 156', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 3.341397', ' mean_absolute_error': ' 57.095154', ' mean_q': ' 114.918'}\n",
      "{'episode': ' 157', ' episode steps': ' 346', ' episode reward': ' 346.000', ' loss': ' 4.614096', ' mean_absolute_error': ' 56.782242', ' mean_q': ' 114.377'}\n",
      "{'episode': ' 158', ' episode steps': ' 458', ' episode reward': ' 458.000', ' loss': ' 7.074708', ' mean_absolute_error': ' 56.650791', ' mean_q': ' 113.871'}\n",
      "{'episode': ' 159', ' episode steps': ' 356', ' episode reward': ' 356.000', ' loss': ' 7.149241', ' mean_absolute_error': ' 56.349609', ' mean_q': ' 113.276'}\n",
      "{'episode': ' 160', ' episode steps': ' 427', ' episode reward': ' 427.000', ' loss': ' 5.580923', ' mean_absolute_error': ' 56.293774', ' mean_q': ' 113.200'}\n",
      "{'episode': ' 161', ' episode steps': ' 332', ' episode reward': ' 332.000', ' loss': ' 4.579061', ' mean_absolute_error': ' 56.028416', ' mean_q': ' 112.790'}\n",
      "{'episode': ' 162', ' episode steps': ' 313', ' episode reward': ' 313.000', ' loss': ' 8.333429', ' mean_absolute_error': ' 55.917332', ' mean_q': ' 112.330'}\n",
      "{'episode': ' 163', ' episode steps': ' 382', ' episode reward': ' 382.000', ' loss': ' 4.079334', ' mean_absolute_error': ' 55.588089', ' mean_q': ' 112.037'}\n",
      "{'episode': ' 164', ' episode steps': ' 328', ' episode reward': ' 328.000', ' loss': ' 5.484010', ' mean_absolute_error': ' 55.531219', ' mean_q': ' 111.644'}\n",
      "{'episode': ' 165', ' episode steps': ' 431', ' episode reward': ' 431.000', ' loss': ' 7.016966', ' mean_absolute_error': ' 55.541031', ' mean_q': ' 111.580'}\n",
      "{'episode': ' 166', ' episode steps': ' 341', ' episode reward': ' 341.000', ' loss': ' 7.278677', ' mean_absolute_error': ' 55.330990', ' mean_q': ' 110.998'}\n",
      "{'episode': ' 167', ' episode steps': ' 398', ' episode reward': ' 398.000', ' loss': ' 7.087126', ' mean_absolute_error': ' 55.133873', ' mean_q': ' 110.779'}\n",
      "{'episode': ' 168', ' episode steps': ' 471', ' episode reward': ' 471.000', ' loss': ' 6.771763', ' mean_absolute_error': ' 54.837563', ' mean_q': ' 110.228'}\n",
      "{'episode': ' 169', ' episode steps': ' 496', ' episode reward': ' 496.000', ' loss': ' 7.970106', ' mean_absolute_error': ' 54.635006', ' mean_q': ' 109.722'}\n",
      "{'episode': ' 170', ' episode steps': ' 491', ' episode reward': ' 491.000', ' loss': ' 5.704204', ' mean_absolute_error': ' 54.260590', ' mean_q': ' 109.047'}\n",
      "{'episode': ' 171', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 7.200768', ' mean_absolute_error': ' 54.098209', ' mean_q': ' 108.654'}\n",
      "{'episode': ' 172', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.464919', ' mean_absolute_error': ' 54.360081', ' mean_q': ' 109.216'}\n",
      "{'episode': ' 173', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.186774', ' mean_absolute_error': ' 53.783821', ' mean_q': ' 108.131'}\n",
      "{'episode': ' 174', ' episode steps': ' 429', ' episode reward': ' 429.000', ' loss': ' 4.830243', ' mean_absolute_error': ' 54.135418', ' mean_q': ' 108.937'}\n",
      "{'episode': ' 175', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 7.292828', ' mean_absolute_error': ' 54.103619', ' mean_q': ' 108.625'}\n",
      "{'episode': ' 176', ' episode steps': ' 477', ' episode reward': ' 477.000', ' loss': ' 6.350655', ' mean_absolute_error': ' 53.979561', ' mean_q': ' 108.621'}\n",
      "{'episode': ' 177', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.235330', ' mean_absolute_error': ' 54.053059', ' mean_q': ' 108.718'}\n",
      "{'episode': ' 178', ' episode steps': ' 499', ' episode reward': ' 499.000', ' loss': ' 5.833961', ' mean_absolute_error': ' 54.018051', ' mean_q': ' 108.660'}\n",
      "{'episode': ' 179', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.821904', ' mean_absolute_error': ' 54.205986', ' mean_q': ' 109.010'}\n",
      "{'episode': ' 180', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.201680', ' mean_absolute_error': ' 54.211395', ' mean_q': ' 109.014'}\n",
      "{'episode': ' 181', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.375962', ' mean_absolute_error': ' 54.281094', ' mean_q': ' 109.005'}\n",
      "{'episode': ' 182', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.382715', ' mean_absolute_error': ' 54.226540', ' mean_q': ' 108.944'}\n",
      "{'episode': ' 183', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.900445', ' mean_absolute_error': ' 54.141014', ' mean_q': ' 108.887'}\n",
      "{'episode': ' 184', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.648526', ' mean_absolute_error': ' 54.440849', ' mean_q': ' 109.243'}\n",
      "{'episode': ' 185', ' episode steps': ' 440', ' episode reward': ' 440.000', ' loss': ' 4.240374', ' mean_absolute_error': ' 53.966129', ' mean_q': ' 108.517'}\n",
      "{'episode': ' 186', ' episode steps': ' 327', ' episode reward': ' 327.000', ' loss': ' 2.932429', ' mean_absolute_error': ' 54.022423', ' mean_q': ' 108.469'}\n",
      "{'episode': ' 187', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.913231', ' mean_absolute_error': ' 53.785702', ' mean_q': ' 108.030'}\n",
      "{'episode': ' 188', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.370584', ' mean_absolute_error': ' 53.921318', ' mean_q': ' 108.256'}\n",
      "{'episode': ' 189', ' episode steps': ' 453', ' episode reward': ' 453.000', ' loss': ' 4.394953', ' mean_absolute_error': ' 53.683739', ' mean_q': ' 107.851'}\n",
      "{'episode': ' 190', ' episode steps': ' 434', ' episode reward': ' 434.000', ' loss': ' 4.740616', ' mean_absolute_error': ' 53.448002', ' mean_q': ' 107.293'}\n",
      "{'episode': ' 191', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 5.950387', ' mean_absolute_error': ' 53.467194', ' mean_q': ' 107.309'}\n",
      "{'episode': ' 192', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 3.836204', ' mean_absolute_error': ' 53.114296', ' mean_q': ' 106.746'}\n",
      "{'episode': ' 193', ' episode steps': ' 308', ' episode reward': ' 308.000', ' loss': ' 3.644928', ' mean_absolute_error': ' 52.884850', ' mean_q': ' 106.207'}\n",
      "{'episode': ' 194', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 4.523789', ' mean_absolute_error': ' 52.529846', ' mean_q': ' 105.522'}\n",
      "{'episode': ' 195', ' episode steps': ' 345', ' episode reward': ' 345.000', ' loss': ' 5.533070', ' mean_absolute_error': ' 52.417603', ' mean_q': ' 105.200'}\n",
      "{'episode': ' 196', ' episode steps': ' 250', ' episode reward': ' 250.000', ' loss': ' 3.804307', ' mean_absolute_error': ' 52.173004', ' mean_q': ' 104.850'}\n",
      "{'episode': ' 197', ' episode steps': ' 398', ' episode reward': ' 398.000', ' loss': ' 4.982242', ' mean_absolute_error': ' 52.211079', ' mean_q': ' 104.764'}\n",
      "{'episode': ' 198', ' episode steps': ' 500', ' episode reward': ' 500.000', ' loss': ' 6.029026', ' mean_absolute_error': ' 52.104034', ' mean_q': ' 104.495'}\n"
     ]
    }
   ],
   "source": [
    "dqn = make_csv(\"DQN_metrics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duel_DQN_metrics.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
